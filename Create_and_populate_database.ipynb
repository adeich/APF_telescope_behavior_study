{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import sqlite3\n",
    "global_sqlite_filename='apf.db'\n",
    "import pandas\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from sqlalchemy import create_engine\n",
    "import pytz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT\n"
     ]
    }
   ],
   "source": [
    "class col_types:\n",
    "    def __init__(self):\n",
    "        self.TEXT = 'TEXT'\n",
    "        self.INTEGER = 'INTEGER'\n",
    "        self.REAL = 'REAL'\n",
    "        self.BLOB = 'BLOB'\n",
    "        self.NULL = 'NULL'\n",
    "        \n",
    "ct = col_types()\n",
    "print(ct.TEXT)\n",
    "\n",
    "#print(os.getcwd())\n",
    "#print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(sqlite_filename=global_sqlite_filename):\n",
    "    conn = sqlite3.connect(sqlite_filename)\n",
    "    cursor = conn.cursor()\n",
    "    return cursor\n",
    "       \n",
    "def get_telemetry_columns():\n",
    "    columns = {'DateTime': ct.TEXT, \n",
    "                  'TARGET': ct.NULL,\n",
    "                  'MIDPTFIN': ct.REAL,\n",
    "                  'AZ': ct.REAL,\n",
    "                  'EL': ct.REAL,\n",
    "                  'AZENCPOS': ct.REAL,\n",
    "                  'ELENCPOS': ct.REAL,\n",
    "                  'AZENCVEL': ct.REAL,\n",
    "                  'ELENCVEL': ct.REAL,\n",
    "                  'AZFLWERR': ct.REAL,\n",
    "                  'ELFLWERR': ct.REAL,\n",
    "                  'OUTFILE': ct.REAL,\n",
    "                  'OBSNUM': ct.REAL,\n",
    "                  'MODE': ct.REAL,\n",
    "                  'AVG_FWHM': ct.REAL,\n",
    "                  'M5WIND': ct.REAL,\n",
    "                  'M5WINDAZ': ct.REAL,\n",
    "                  'TAVERAGE': ct.REAL,\n",
    "                  'TM1S210': ct.REAL,\n",
    "                  'TM2CAIR': ct.REAL,\n",
    "                  'OFFSET_AZ': ct.REAL,\n",
    "                  'OFFSET_EL': ct.REAL,\n",
    "                  'RMSOFFSET_AZ': ct.REAL,\n",
    "                  'RMSOFFSET_EL': ct.REAL,\n",
    "                  'AVGOFFSET_AZ': ct.REAL,\n",
    "                  'AVGOFFSET_EL': ct.REAL,\n",
    "                  'HATCHPOS': ct.TEXT,\n",
    "                  'EVENT': ct.TEXT}    \n",
    "    return columns\n",
    "    \n",
    "def get_velocity_columns():\n",
    "    columns = [('MdptJulian', ct.REAL),\n",
    "               ('velocity', ct.REAL),\n",
    "               ('velocity_error', ct.REAL),\n",
    "               ('stellar_activity1', ct.REAL),\n",
    "               ('stellar_activity2', ct.REAL),\n",
    "               ('total_counts', ct.REAL),\n",
    "               ('brad_doesnt_know', ct.REAL),\n",
    "               ('DateTimeUTC', ct.TEXT),\n",
    "               ('DateTimeLocal', ct.TEXT),\n",
    "               ('starID', ct.TEXT)\n",
    "              ]\n",
    "    return columns\n",
    "    \n",
    "def create_telemetry_table(cursor):        \n",
    "    columns = get_telemetry_columns()\n",
    "    l = ['{} {}'.format(k,v) for (k, v) in columns.items()]\n",
    "    print(len(l))\n",
    "    full_list = ', '.join(l)\n",
    "    sql_create_string = 'CREATE TABLE telemetry (' + full_list + ', PRIMARY KEY (DateTime))'\n",
    "    print(sql_create_string)        \n",
    "    cursor.execute(sql_create_string)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def create_velocity_table(cursor):\n",
    "    columns = get_velocity_columns()\n",
    "    l = ['{} {}'.format(k,v) for (k, v) in columns]\n",
    "    full_list = ', '.join(l)\n",
    "    sql_create_string = 'CREATE TABLE velocity (' + full_list + ', PRIMARY KEY (DateTimeLocal))'\n",
    "    print(sql_create_string)  \n",
    "    cursor.execute(sql_create_string)\n",
    "\n",
    "    return\n",
    "\n",
    "def open_connection(sqlite_filename=global_sqlite_filename):\n",
    "    dburi = 'file:{}?mode=rw'.format(sqlite_filename)\n",
    "    conn = sqlite3.connect(dburi, uri=True)\n",
    "    return conn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = open_connection()\n",
    "cursor = conn.cursor()\n",
    "#create_telemetry_table(cursor)\n",
    "#create_velocity_table(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_telemetry_table(conn, filenames):\n",
    "    for csv_file in filenames:\n",
    "        try:\n",
    "            df = pandas.read_csv(csv_file, \n",
    "                               sep='\\t', skiprows=1, header=None, names=get_telemetry_columns(), comment='#')\n",
    "            df.to_sql('telemetry', conn, if_exists='append', index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(csv_file)\n",
    "            print(e)\n",
    "\n",
    "def populate_telemetry(conn=None, dirname=None, batchsize=5):\n",
    "    filenames = [os.path.join(dirname, x) for x in os.listdir(dirname)]\n",
    "    filenames.sort()\n",
    "    \n",
    "    def batch(iterable, n=1):\n",
    "        l = len(iterable)\n",
    "        for ndx in range(0, l, n):\n",
    "            yield iterable[ndx : min(ndx + n, l)]\n",
    "    \n",
    "    for file_batch in batch(filenames, n=batchsize):\n",
    "        populate_telemetry_table(conn, file_batch)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate_telemetry(conn, '../telemetry_data', batchsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_velocity_csv(dirname, filename):\n",
    "    full_path = os.path.join(dirname, filename)\n",
    "    columns = get_velocity_columns()[:-2] # leave off the last two column names\n",
    "                                        # because we're calculating them below.\n",
    "    df = pandas.read_csv(full_path, sep='\\s+',\n",
    "            names=[x[0] for x in columns]) \n",
    "                                                \n",
    "    return df\n",
    "    \n",
    "    \n",
    "california_tzinfo = pytz.timezone('US/Pacific')\n",
    "\n",
    "# returns a string for a single julian date. Couldn't figure out how to vectorize.\n",
    "def convert_julian_to_datetime_local(juliantime):\n",
    "    times = Time(juliantime, format='jd')\n",
    "    full_iso = times.to_datetime(timezone=california_tzinfo).isoformat()\n",
    "    return full_iso[:-6]\n",
    "\n",
    "# takes in an array of julian dates. Returns an array of local isot strings.\n",
    "def make_array_of_local_datetimes(julian_array):\n",
    "    output_array = output_array = np.chararray(len(julian_array), itemsize=26, unicode=True)\n",
    "    for i, julian_time in enumerate(julian_array):\n",
    "        output_array[i] = convert_julian_to_datetime_local(julian_time)\n",
    "    return output_array\n",
    "    \n",
    "\n",
    "def convert_julian_to_datetime_utc(juliantimes):\n",
    "    times = Time(juliantimes, format='jd')\n",
    "    return times.isot \n",
    "    \n",
    "def add_calculated_columns(df, filename):\n",
    "    new_df = df.copy()\n",
    "    #datetimes = convert_julian_to_datetime(new_df.MdptJulian)\n",
    "    new_df['DateTimeUTC'] = convert_julian_to_datetime_utc(new_df.MdptJulian)\n",
    "    new_df['DateTimeLocal'] = make_array_of_local_datetimes(new_df.MdptJulian)\n",
    "    new_df['starID'] = [filename] * len(new_df.index) \n",
    "    \n",
    "    return new_df\n",
    "    \n",
    "\n",
    "def populate_velocity(conn, dirname='../standard_star_velocity_measurements/', debug=False):\n",
    "    filenames = ['HD10700_APF.vels', 'HD185144_APF.vels', 'HD9407_APF.vels']\n",
    "    for file in filenames:\n",
    "        print('started {}'.format(file))\n",
    "        df_incomplete = load_velocity_csv(dirname, file)\n",
    "        df_complete = add_calculated_columns(df_incomplete, file)\n",
    "        if debug:\n",
    "            print(df_complete)\n",
    "        else: \n",
    "            df_complete.to_sql('velocity', conn, if_exists='append', index=False)\n",
    "        print('tried to add {} entries to \\'velocity\\''.format(len(df_complete)))\n",
    "\n",
    "#velocity_df = load_velocity_csv('../standard_star_velocity_measurements/', 'HD10700_APF.vels')\n",
    "#add_calculated_columns(velocity_df, 'HD10700_APF.vels' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started HD10700_APF.vels\n",
      "tried to add 755 entries to 'velocity'\n",
      "started HD185144_APF.vels\n",
      "tried to add 1655 entries to 'velocity'\n",
      "started HD9407_APF.vels\n",
      "tried to add 694 entries to 'velocity'\n"
     ]
    }
   ],
   "source": [
    "#populate_velocity(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create additional calculated columns on velocity\n",
    "engine = create_engine('sqlite:///apf.db', echo=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   epocseconds - 1436589861.0       Event\n",
      "0                       -38.0  EraseBegin\n"
     ]
    }
   ],
   "source": [
    "#add new table telemetrytimelookup\n",
    "def drop_telemetry_time_lookup(engine):\n",
    "    engine.execute(\"\"\"DROP TABLE IF EXISTS telemetry_time_lookup;\"\"\")\n",
    "    print('dropped telemetry_time_lookup.')\n",
    "\n",
    "def create_telemetry_time_lookup(engine):\n",
    "    engine.execute(\"\"\"\n",
    "    CREATE TABLE telemetry_time_lookup (\n",
    "    DateTime TEXT PRIMARY KEY,\n",
    "    YearMonthDayHour REAL,\n",
    "    EpocSeconds REAL,\n",
    "    Event TEXT,\n",
    "    ExposureID TEXT,\n",
    "    FOREIGN KEY (DateTime) REFERENCES telemetry(DateTime) \n",
    "    )\"\"\")\n",
    "    print('created telemetry_time_lookup.')\n",
    "\n",
    "def populate_telemetry_time_lookup(engine):   \n",
    "    engine.execute(\"\"\"INSERT INTO telemetry_time_lookup (DateTime,\n",
    "        YearMonthDayHour, EpocSeconds, Event) \n",
    "    SELECT t.DateTime, strftime('%Y-%m-%d-%H', t.datetime), strftime('%s', t.DateTime), t.Event\n",
    "    from telemetry t\n",
    "    \"\"\")\n",
    "    print('populated created telemetry_time_lookup.')\n",
    "    \n",
    "\n",
    "def create_index_in_telemetry_time_lookup(engine):\n",
    "    engine.execute(\"\"\"CREATE INDEX idx_yearmonthdayhour ON \n",
    "        telemetry_time_lookup(YearMonthDayHour, EpocSeconds)\n",
    "    \"\"\")\n",
    "    print('created index on YearMonthDayHour in TTC.')\n",
    "    \n",
    "#drop_telemetry_time_lookup(engine)\n",
    "#create_telemetry_time_lookup(engine)\n",
    "#populate_telemetry_time_lookup(engine)\n",
    "#create_index_in_telemetry_time_lookup(engine)\n",
    "\n",
    "df = pandas.read_sql_query(\"\"\"select epocseconds - 1436589861.0, event from (select * from telemetry_time_lookup\n",
    "    where YearMonthDayHour = '2015-07-11-04') \n",
    "    where event != 'ExposureBegin' \n",
    "    and epocseconds - 1436589861.0 < 0\n",
    "    order by  abs(1436589861.0 - epocseconds) \n",
    "    limit 1\n",
    "    \"\"\", con=engine)\n",
    "pandas.set_option('precision', 18)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 2017-01-31T21:40:17.184006\n",
      "no telemetry for this time 2017-01-31T06:59:59.0187\n",
      "trying 2017-01-31T22:05:37.823997\n",
      "no telemetry for this time 2017-01-31T06:59:59.0187\n",
      "trying 2017-01-31T22:25:00.768001\n",
      "no telemetry for this time 2017-01-31T06:59:59.0187\n",
      "trying 2017-03-17T20:38:08.736007\n",
      "2017-03-17T20:27:39.0170 2017-03-17T20:47:29.0238\n",
      "trying 2017-03-17T20:58:02.784006\n",
      "2017-03-17T20:48:15.0185 2017-03-17T21:08:00.8703\n",
      "trying 2017-04-03T05:36:37.151993\n",
      "2017-04-03T05:26:06.0192 2017-04-03T05:46:05.0192\n",
      "trying 2017-04-03T05:57:11.808020\n",
      "2017-04-03T05:46:52.0172 2017-04-03T06:06:50.6034\n",
      "trying 2017-06-04T03:07:12.288006\n",
      "2017-06-04T02:57:24.1555 2017-06-04T03:17:23.7304\n",
      "trying 2017-06-04T03:28:14.592002\n",
      "2017-06-04T03:18:08.3040 2017-06-04T03:38:08.0164\n",
      "trying 2017-06-21T04:58:37.920019\n",
      "2017-06-21T04:48:45.0159 2017-06-21T05:08:43.0119\n",
      "trying 2017-06-25T04:51:43.199999\n",
      "2017-06-25T04:41:33.0142 2017-06-25T05:01:32.2863\n",
      "trying 2017-06-30T04:34:16.895998\n",
      "2017-06-30T04:24:07.5479 2017-06-30T04:44:06.0106\n",
      "trying 2017-06-30T04:54:52.416032\n",
      "2017-06-30T04:44:52.0224 2017-06-30T05:04:51.0154\n",
      "trying 2017-07-01T01:28:26.976029\n",
      "2017-06-30T06:56:09.0082 2017-06-30T06:59:59.0058\n",
      "trying 2017-07-01T01:46:51.167988\n",
      "2017-06-30T06:56:09.0082 2017-06-30T06:59:59.0058\n",
      "trying 2017-07-12T03:52:48.576001\n",
      "2017-07-12T03:42:49.0203 2017-07-12T04:02:48.0176\n",
      "trying 2017-07-12T04:13:24.095994\n",
      "2017-07-12T04:03:33.9633 2017-07-12T04:23:32.7991\n",
      "trying 2017-07-12T04:31:50.880013\n",
      "2017-07-12T04:24:18.0288 2017-07-12T04:44:17.2898\n",
      "trying 2017-07-15T01:13:30.144000\n",
      "2017-07-15T01:03:49.0307 2017-07-15T01:23:48.0638\n",
      "trying 2017-07-15T01:35:01.823978\n",
      "2017-07-15T01:24:34.0266 2017-07-15T01:44:32.6519\n",
      "trying 2017-07-26T02:43:32.736019\n",
      "2017-07-26T02:33:43.7912 2017-07-26T02:53:42.3994\n",
      "trying 2017-07-26T03:04:54.912006\n",
      "2017-07-26T02:54:29.0076 2017-07-26T03:14:27.3695\n",
      "trying 2017-07-29T02:32:20.543970\n",
      "2017-07-29T02:22:17.0411 2017-07-29T02:42:17.0142\n",
      "trying 2017-07-29T02:53:01.248003\n",
      "2017-07-29T02:43:03.0260 2017-07-29T03:03:02.0243\n",
      "trying 2017-08-05T03:04:02.208007\n",
      "2017-08-05T02:53:58.0582 2017-08-05T03:13:58.0285\n",
      "trying 2017-08-05T03:24:22.176003\n",
      "2017-08-05T03:14:44.0308 2017-08-05T03:34:42.9462\n",
      "trying 2017-08-12T23:50:43.007997\n",
      "2017-08-12T23:40:58.0275 2017-08-13T00:00:56.3919\n",
      "trying 2017-08-13T00:11:29.759995\n",
      "2017-08-13T00:01:42.5565 2017-08-13T00:21:41.0312\n",
      "trying 2017-08-23T01:27:33.408024\n",
      "2017-08-23T01:17:15.0346 2017-08-23T01:37:14.0240\n",
      "trying 2017-08-23T01:45:53.279990\n",
      "2017-08-23T01:38:01.0375 2017-08-23T01:57:59.0313\n",
      "trying 2017-08-28T23:49:34.752000\n",
      "2017-08-28T23:39:37.6218 2017-08-28T23:59:36.0263\n",
      "trying 2017-08-29T00:10:15.456033\n",
      "2017-08-29T00:00:24.0243 2017-08-29T00:20:21.0302\n",
      "trying 2017-09-07T01:07:37.632011\n",
      "2017-09-07T01:04:01.0247 2017-09-07T01:10:57.0315\n",
      "trying 2017-09-07T01:15:58.752005\n",
      "2017-09-07T01:11:43.0280 2017-09-07T01:19:57.0271\n",
      "trying 2017-09-07T01:26:30.336026\n",
      "2017-09-07T01:20:43.0312 2017-09-07T01:31:57.5002\n",
      "trying 2017-09-09T23:44:22.847999\n",
      "2017-09-09T23:34:32.0381 2017-09-09T23:54:31.5377\n",
      "trying 2017-09-10T00:05:00.096005\n",
      "2017-09-09T23:55:17.0263 2017-09-10T00:15:15.0220\n",
      "trying 2017-09-16T23:46:03.071997\n",
      "2017-09-16T23:35:49.0365 2017-09-16T23:55:48.0266\n",
      "trying 2017-09-17T00:06:24.768006\n",
      "2017-09-16T23:56:34.0314 2017-09-17T00:16:32.0294\n",
      "trying 2017-09-17T00:27:19.296024\n",
      "2017-09-17T00:17:18.0218 2017-09-17T00:37:17.0297\n",
      "trying 2017-09-26T21:47:54.816017\n",
      "2017-09-26T21:37:48.4843 2017-09-26T21:57:48.4465\n",
      "trying 2017-09-26T22:08:44.159995\n",
      "2017-09-26T21:58:33.6340 2017-09-26T22:18:32.4609\n",
      "trying 2017-10-02T22:17:36.383984\n",
      "2017-10-02T22:07:33.0187 2017-10-02T22:27:31.0172\n",
      "trying 2017-10-02T22:38:09.311998\n",
      "2017-10-02T22:28:16.0274 2017-10-02T22:48:15.0320\n",
      "trying 2017-10-09T23:17:19.391989\n",
      "2017-10-09T23:07:12.7319 2017-10-09T23:27:11.0167\n",
      "trying 2017-10-09T23:37:49.728023\n",
      "2017-10-09T23:27:57.0340 2017-10-09T23:47:56.0265\n",
      "trying 2017-10-17T03:33:20.447997\n",
      "2017-10-17T03:23:20.0258 2017-10-17T03:43:18.5647\n",
      "trying 2017-10-17T03:54:33.983999\n",
      "2017-10-17T03:44:05.0242 2017-10-17T04:04:03.0325\n",
      "trying 2017-10-24T03:40:09.120011\n",
      "2017-10-24T03:30:46.0215 2017-10-24T03:50:45.0218\n",
      "trying 2017-10-24T04:01:14.016027\n",
      "2017-10-24T03:51:31.0180 2017-10-24T04:11:30.0299\n",
      "trying 2017-10-27T21:39:15.552006\n",
      "2017-10-27T21:29:16.0294 2017-10-27T21:49:15.0268\n",
      "trying 2017-10-27T21:59:57.120005\n",
      "2017-10-27T21:50:01.0322 2017-10-27T22:10:00.7899\n",
      "trying 2017-11-06T18:04:22.368013\n",
      "2017-11-06T17:54:29.7966 2017-11-06T18:14:29.0271\n",
      "trying 2017-11-06T18:24:06.911980\n",
      "2017-11-06T18:15:15.0280 2017-11-06T18:32:28.0306\n",
      "trying 2017-11-18T17:56:47.040006\n",
      "2017-11-18T17:46:49.9565 2017-11-18T18:06:48.0192\n",
      "trying 2017-11-18T18:17:13.056007\n",
      "2017-11-18T18:07:34.0229 2017-11-18T18:27:32.7017\n",
      "trying 2017-11-27T21:43:46.271988\n",
      "2017-11-27T21:33:28.2208 2017-11-27T21:53:27.4660\n",
      "trying 2017-11-27T22:03:44.639980\n",
      "2017-11-27T21:54:13.0254 2017-11-27T22:14:12.0345\n",
      "trying 2017-11-27T22:25:12.000006\n",
      "2017-11-27T22:14:59.0195 2017-11-27T22:34:57.0509\n",
      "trying 2017-12-01T19:25:56.928027\n",
      "2017-12-01T19:16:35.0324 2017-12-01T19:36:33.0291\n",
      "trying 2017-12-01T19:47:59.712000\n",
      "2017-12-01T19:37:19.0294 2017-12-01T19:57:18.4669\n",
      "trying 2017-12-09T19:44:18.528006\n",
      "2017-12-09T19:33:52.0255 2017-12-09T19:53:49.0301\n",
      "trying 2017-12-09T20:04:36.767989\n",
      "2017-12-09T19:54:37.7649 2017-12-09T20:14:35.9435\n",
      "trying 2017-12-17T19:22:12.288006\n",
      "2017-12-17T19:11:33.0260 2017-12-17T19:31:32.0250\n",
      "trying 2017-12-17T19:43:22.368021\n",
      "2017-12-17T19:32:19.0178 2017-12-17T19:52:17.0277\n",
      "trying 2017-12-17T20:03:00.863982\n",
      "2017-12-17T19:53:03.0320 2017-12-17T20:13:02.1070\n",
      "trying 2017-12-26T20:50:36.384000\n",
      "2017-12-26T20:41:00.0224 2017-12-26T21:00:58.0313\n",
      "trying 2017-12-26T21:12:59.040004\n",
      "2017-12-26T21:01:43.0266 2017-12-26T21:21:42.0931\n",
      "trying 2018-02-04T21:23:58.271995\n",
      "2018-02-04T21:14:12.0333 2018-02-04T21:34:11.2175\n",
      "trying 2018-02-04T21:44:41.568007\n",
      "2018-02-04T21:34:58.0373 2018-02-04T21:54:55.1558\n",
      "trying 2018-02-04T22:05:29.183972\n",
      "2018-02-04T21:55:41.0166 2018-02-04T22:15:40.0354\n",
      "trying 2018-04-24T04:14:47.903988\n",
      "2018-04-24T04:04:36.0331 2018-04-24T04:24:35.0361\n",
      "trying 2018-04-24T04:35:41.567999\n",
      "2018-04-24T04:25:21.0222 2018-04-24T04:45:19.0268\n",
      "trying 2018-05-20T01:45:27.359994\n",
      "2018-05-20T01:35:41.0385 2018-05-20T01:55:40.7197\n",
      "trying 2018-05-21T02:08:21.119994\n",
      "2018-05-21T01:57:33.0274 2018-05-21T02:17:31.3612\n",
      "trying 2018-05-21T02:28:23.808019\n",
      "2018-05-21T02:18:17.0247 2018-05-21T02:38:15.0427\n",
      "trying 2018-07-29T03:01:48.287993\n",
      "2018-07-29T02:54:24.0870 2018-07-29T03:10:07.8209\n",
      "trying 2018-07-29T03:18:25.343981\n",
      "2018-07-29T03:10:54.0955 2018-07-29T03:27:00.0192\n",
      "trying 2018-08-01T04:10:56.351995\n",
      "2018-08-01T17:00:00.0000 2018-07-31T06:59:59.0459\n",
      "trying 2018-08-01T04:21:32.256010\n",
      "2018-08-01T17:00:00.0000 2018-07-31T06:59:59.0459\n",
      "trying 2018-08-04T02:20:14.783996\n",
      "2018-08-04T02:12:50.0199 2018-08-04T02:27:40.8098\n",
      "trying 2018-08-04T02:35:53.088020\n",
      "2018-08-04T02:28:26.0197 2018-08-04T02:43:52.4897\n",
      "trying 2018-08-07T02:21:46.368010\n",
      "2018-08-07T02:14:29.4702 2018-08-07T02:28:25.0158\n",
      "trying 2018-08-07T02:36:13.823977\n",
      "2018-08-07T02:29:11.6733 2018-08-07T02:43:48.6311\n",
      "trying 2018-08-20T02:22:38.208002\n",
      "2018-08-20T02:16:37.0276 2018-08-20T02:28:17.8006\n",
      "trying 2018-08-20T02:34:24.959992\n",
      "2018-08-20T02:29:04.0232 2018-08-20T02:39:36.0676\n",
      "trying 2018-08-30T01:12:39.168014\n",
      "2018-08-30T01:06:08.0191 2018-08-30T01:19:02.0884\n",
      "trying 2018-08-30T01:25:35.903974\n",
      "2018-08-30T01:19:48.0203 2018-08-30T01:31:31.2838\n",
      "trying 2018-08-31T02:16:15.456025\n",
      "2018-08-31T02:11:37.0315 2018-08-31T02:20:56.4673\n",
      "trying 2018-08-31T02:26:17.663983\n",
      "2018-08-31T02:21:41.0488 2018-08-31T02:30:38.0254\n",
      "trying 2018-08-31T02:36:00.863999\n",
      "2018-08-31T02:31:24.4586 2018-08-31T02:40:32.3556\n",
      "trying 2018-09-01T04:42:04.320017\n",
      "2018-08-31T06:59:59.0203 2018-08-31T06:59:59.0203\n",
      "trying 2018-09-01T04:55:27.840020\n",
      "2018-08-31T06:59:59.0203 2018-08-31T06:59:59.0203\n",
      "trying 2018-09-05T00:30:27.648009\n",
      "2018-09-05T00:24:16.6714 2018-09-05T00:36:26.7657\n",
      "trying 2018-09-05T00:43:09.696018\n",
      "2018-09-05T00:37:13.0328 2018-09-05T00:49:09.0162\n",
      "trying 2018-09-06T01:28:46.848020\n",
      "2018-09-06T01:22:47.5583 2018-09-06T01:34:24.7424\n",
      "trying 2018-09-06T01:39:52.128016\n",
      "2018-09-06T01:35:10.3061 2018-09-06T01:44:40.2700\n",
      "trying 2018-09-09T00:08:55.103984\n",
      "2018-09-09T00:03:42.7746 2018-09-09T00:14:16.0349\n",
      "trying 2018-09-09T00:20:15.072012\n",
      "2018-09-09T00:15:01.0173 2018-09-09T00:25:39.0173\n",
      "trying 2018-09-10T02:37:21.216007\n",
      "2018-09-10T02:32:45.0187 2018-09-10T02:42:03.0136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 2018-09-10T02:47:43.295996\n",
      "2018-09-10T02:42:49.6988 2018-09-10T02:52:32.1132\n",
      "trying 2018-09-11T22:52:35.039991\n",
      "2018-09-11T22:48:01.5423 2018-09-11T22:56:41.4772\n",
      "trying 2018-09-11T23:02:37.247990\n",
      "2018-09-11T22:57:27.0277 2018-09-11T23:07:44.9722\n",
      "trying 2018-09-11T23:13:38.207994\n",
      "2018-09-11T23:08:31.0279 2018-09-11T23:18:24.3267\n",
      "trying 2018-09-13T01:57:27.936009\n",
      "2018-09-13T01:49:53.0254 2018-09-13T02:04:53.4341\n",
      "trying 2018-09-13T02:12:44.639989\n",
      "2018-09-13T02:05:38.7818 2018-09-13T02:19:43.0223\n",
      "trying 2018-09-14T01:53:12.191993\n",
      "2018-09-14T01:46:38.7362 2018-09-14T01:59:31.5597\n",
      "trying 2018-09-14T02:06:51.263993\n",
      "2018-09-14T02:00:18.0257 2018-09-14T02:13:32.0282\n",
      "trying 2018-09-16T01:48:46.080018\n",
      "2018-09-16T01:43:41.0228 2018-09-16T01:54:19.8965\n",
      "trying 2018-09-16T02:00:44.063973\n",
      "2018-09-16T01:55:06.0200 2018-09-16T02:06:22.0371\n",
      "trying 2018-09-19T01:19:43.391985\n",
      "2018-09-19T01:14:45.0232 2018-09-19T01:24:51.0246\n",
      "trying 2018-09-19T01:30:53.856021\n",
      "2018-09-19T01:25:37.0287 2018-09-19T01:36:20.9799\n",
      "trying 2018-09-21T01:19:39.935999\n",
      "2018-09-21T01:14:11.0180 2018-09-21T01:25:15.0079\n",
      "trying 2018-09-21T01:31:22.367997\n",
      "2018-09-21T01:26:01.0158 2018-09-21T01:36:51.0151\n",
      "trying 2018-09-21T22:59:55.680007\n",
      "2018-09-21T22:54:20.9564 2018-09-21T23:05:48.0804\n",
      "trying 2018-09-21T23:12:14.400000\n",
      "2018-09-21T23:06:33.0200 2018-09-21T23:17:42.0293\n",
      "trying 2018-09-23T01:19:34.752000\n",
      "2018-09-23T01:14:05.6659 2018-09-23T01:25:03.2755\n",
      "trying 2018-09-23T01:31:13.728012\n",
      "2018-09-23T01:25:48.0229 2018-09-23T01:36:44.5289\n",
      "trying 2018-09-25T00:34:28.703994\n",
      "2018-09-25T00:28:21.8398 2018-09-25T00:40:24.0208\n",
      "trying 2018-09-25T00:47:04.703997\n",
      "2018-09-25T00:41:09.0154 2018-09-25T00:53:04.0183\n",
      "trying 2018-09-27T01:00:29.952013\n",
      "2018-09-27T00:54:07.0275 2018-09-27T01:06:40.3669\n",
      "trying 2018-09-27T01:13:29.279993\n",
      "2018-09-27T01:07:25.9976 2018-09-27T01:19:35.0336\n",
      "trying 2018-10-06T02:11:07.871976\n",
      "2018-10-06T02:02:22.6913 2018-10-06T02:19:03.5105\n",
      "trying 2018-10-06T02:28:35.903990\n",
      "2018-10-06T02:19:49.0250 2018-10-06T02:37:35.0227\n",
      "trying 2018-10-09T23:57:48.959981\n",
      "2018-10-09T23:54:20.0217 2018-10-10T00:01:21.2489\n",
      "trying 2018-10-10T00:06:05.759982\n",
      "2018-10-10T00:02:07.0237 2018-10-10T00:09:48.0292\n",
      "trying 2018-10-10T00:14:26.016009\n",
      "2018-10-10T00:10:34.3790 2018-10-10T00:18:43.7693\n",
      "trying 2018-10-13T02:36:41.471986\n",
      "2018-10-13T02:30:49.5217 2018-10-13T02:42:38.9828\n",
      "trying 2018-10-13T02:49:50.303998\n",
      "2018-10-13T02:43:24.7519 2018-10-13T02:56:41.0272\n",
      "trying 2018-10-14T22:06:58.751997\n",
      "2018-10-14T22:01:11.0292 2018-10-14T22:12:38.4026\n",
      "trying 2018-10-14T22:18:23.040017\n",
      "2018-10-14T22:13:24.0273 2018-10-14T22:23:17.8186\n",
      "trying 2018-10-14T22:29:22.272008\n",
      "2018-10-14T22:24:04.0205 2018-10-14T22:35:11.0232\n",
      "trying 2018-10-16T00:07:13.152013\n",
      "2018-10-16T00:00:41.5817 2018-10-16T00:13:37.1272\n",
      "trying 2018-10-16T00:20:30.623969\n",
      "2018-10-16T00:14:22.3492 2018-10-16T00:26:45.0167\n",
      "trying 2018-10-18T00:08:29.183988\n",
      "2018-10-18T00:03:28.0264 2018-10-18T00:13:27.0315\n",
      "trying 2018-10-18T00:18:59.039996\n",
      "2018-10-18T00:14:13.9135 2018-10-18T00:23:42.0302\n",
      "trying 2018-10-20T00:54:09.791975\n",
      "2018-10-20T00:48:49.0182 2018-10-20T00:59:22.6473\n",
      "trying 2018-10-20T01:05:28.031990\n",
      "2018-10-20T01:00:08.0136 2018-10-20T01:11:11.6777\n",
      "trying 2018-10-22T00:01:57.791985\n",
      "2018-10-21T23:57:09.8561 2018-10-22T00:06:42.0330\n",
      "trying 2018-10-22T00:12:31.103979\n",
      "2018-10-22T00:07:27.0320 2018-10-22T00:17:23.6633\n",
      "trying 2018-10-23T23:18:32.831984\n",
      "2018-10-23T23:13:14.9694 2018-10-23T23:23:37.0297\n",
      "trying 2018-10-23T23:29:18.239990\n",
      "2018-10-23T23:24:22.0310 2018-10-23T23:34:18.9840\n",
      "trying 2018-10-24T23:41:09.311973\n",
      "2018-10-24T23:36:51.0692 2018-10-24T23:45:42.0239\n",
      "trying 2018-10-24T23:51:47.808007\n",
      "2018-10-24T23:46:27.7672 2018-10-24T23:56:56.0228\n",
      "just tried to populate 144 rows of begin-end timestamps\n"
     ]
    }
   ],
   "source": [
    "def drop_vel_telemetry_stats(engine):\n",
    "    engine.execute(\"\"\"DROP TABLE IF EXISTS vel_telemetry_stats;\"\"\")\n",
    "    print('dropped vel_telemetry_stats.')\n",
    "\n",
    "def create_vel_telemetry_stats(engine):\n",
    "    engine.execute(\"\"\"\n",
    "    CREATE TABLE vel_telemetry_stats (\n",
    "                  DateTimeLocal TEXT PRIMARY KEY,\n",
    "                  YearMonthDayHour TEXT,\n",
    "                  EpocSeconds REAL,\n",
    "                  ExposureID TEXT,\n",
    "                  exposure_begin_datetime TEXT,\n",
    "                  exposure_end_datetime TEXT\n",
    "                  EL_AVG REAL, EL_STD REAL,\n",
    "                  AZENCPOS_AVG REAL, AZENCPOS_STD REAL\n",
    "                  ELENCPOS_AVG REAL, ELENCPOS_STD REAL,\n",
    "                  AZENCVEL_AVG REAL, AZENCVEL_STD REAL,\n",
    "                  ELENCVEL_AVG REAL, ELENCVEL_STD REAL,\n",
    "                  AZFLWERR_AVG REAL, AZFLWERR_STD REAL,\n",
    "                  ELFLWERR_AVG REAL, ELFLWERR_STD REAL,\n",
    "                  AVG_FWHM_AVG REAL, AVG_FWHM_STD REAL,\n",
    "                  M5WIND_AVG REAL, M5WIND_STD REAL,\n",
    "                  M5WINDAZ_AVG REAL, M5WINDAZ_STD REAL,\n",
    "                  TAVERAGE_AVG REAL, TAVERAGE_STD REAL,\n",
    "                  TM1S210_AVG REAL, TM1S210_STD REAL,\n",
    "                  TM2CAIR_AVG REAL, TM2CAIR_STD REAL,\n",
    "                  OFFSET_AZ_AVG REAL, OFFSET_AZ_STD REAL,\n",
    "                  OFFSET_EL_AVG REAL, OFFSET_EL_STD REAL,\n",
    "                  RMSOFFSET_AZ_AVG REAL, RMSOFFSET_AZ_STD REAL,\n",
    "                  RMSOFFSET_EL_AVG REAL, RMSOFFSET_EL_STD REAL,\n",
    "                  AVGOFFSET_AZ_AVG REAL, AVGOFFSET_AZ_STD REAL,\n",
    "                  AVGOFFSET_EL_AVG REAL, AVGOFFSET_EL_STD REAL,\n",
    "                  Delta_temp_from_begin_night REAL, \n",
    "    FOREIGN KEY (DateTimeLocal) REFERENCES velocity(DateTimeLocal) \n",
    "    )\"\"\")\n",
    "    print('created vel_telemetry_stats')\n",
    "    return\n",
    "\n",
    "def get_begin_end_exposure_datetimes(YearMonthDayHour, epocseconds, engine):\n",
    "    df_begin = pandas.read_sql_query(\"\"\"select epocseconds - {}, event from (select * from telemetry_time_lookup\n",
    "    where YearMonthDayHour = {1}) \n",
    "    where event != 'ExposureBegin' \n",
    "    and epocseconds - {0} < 0\n",
    "    order by  abs({0} - epocseconds) \n",
    "    limit 1\n",
    "    \"\"\".format(), con=engine)\n",
    "    \n",
    "    df_end = pandas.read_sql_query(\"\"\"select epocseconds - {}, event from (select * from telemetry_time_lookup\n",
    "    where YearMonthDayHour = {1}) \n",
    "    where event != 'ExposureBegin' \n",
    "    and epocseconds - {0} > 0\n",
    "    order by  abs({0} - epocseconds) \n",
    "    limit 1\n",
    "    \"\"\".format(), con=engine)\n",
    "    \n",
    "    return df_begin, df_end\n",
    "\n",
    "def populate_only_datetime_vts(engine):\n",
    "    engine.execute(\"\"\"Insert into vel_telemetry_stats\n",
    "                                    (DateTimeLocal, YearMonthDayHour, EpocSeconds)\n",
    "                                    select v.DateTimeLocal, \n",
    "                                        strftime('%Y-%m-%d-%H', v.DateTimeLocal), \n",
    "                                        strftime('%s', v.DateTimeLocal)\n",
    "                                    from velocity v\n",
    "                                    where v.DateTimeLocal > \"2015-01-01T17:00:00\" \"\"\")\n",
    "    print(pandas.read_sql_query(\"\"\"select * from vel_telemetry_stats order by datetimelocal desc limit 10\"\"\", engine))\n",
    "    \n",
    "def get_begin_end_times(engine, VelocityDateTime, printstuff=False):\n",
    "    DateTime = VelocityDateTime\n",
    "    if printstuff:\n",
    "        print('starting datetime: {}'.format(DateTime))\n",
    "        \n",
    "    def make_sql(DateTime, TrueForBefore=True):\n",
    "        if TrueForBefore:\n",
    "            greaterthan = '<'\n",
    "            ordering = 'desc'\n",
    "        else:\n",
    "            greaterthan = '>'\n",
    "            ordering = 'asc'\n",
    "        output = \"\"\"select datetime, epocseconds - strftime(\"%s\", \"{0}\"), event from \n",
    "            (select * from telemetry_time_lookup where \n",
    "            YearMonthDayHour =  strftime('%Y-%m-%d-%H', \"{0}\" ) \n",
    "        union all\n",
    "            select * from telemetry_time_lookup where \n",
    "            YearMonthDayHour = (select yearmonthdayhour from telemetry_time_lookup \n",
    "                where YearMonthDayHour {1} strftime('%Y-%m-%d-%H', \"{0}\") order by \n",
    "                YearMonthDayHour {2} limit 1)\n",
    "            ) \n",
    "         where event != 'ExposureBegin' \n",
    "            and epocseconds - strftime(\"%s\", \"{0}\") {1} 0\n",
    "            order by  abs(strftime(\"%s\", \"{0}\") - epocseconds) \n",
    "            limit 1\"\"\".format(DateTime, greaterthan, ordering)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    if printstuff:\n",
    "        print(make_sql(VelocityDateTime, TrueForBefore=True))\n",
    "        print(make_sql(VelocityDateTime, TrueForBefore=False))\n",
    "    \n",
    "    df_begin = pandas.read_sql_query(make_sql(VelocityDateTime, TrueForBefore=True), engine)\n",
    "    df_begin1 = pandas.read_sql_query(\"\"\"select datetime, epocseconds - strftime(\"%s\", \"{0}\"), event from \n",
    "            (select * from telemetry_time_lookup where \n",
    "            YearMonthDayHour =  strftime('%Y-%m-%d-%H', \"{0}\" ) \n",
    "        union all\n",
    "            select * from telemetry_time_lookup where \n",
    "            YearMonthDayHour = (select yearmonthdayhour from telemetry_time_lookup \n",
    "                where YearMonthDayHour < strftime('%Y-%m-%d-%H', \"{0}\") order by \n",
    "                YearMonthDayHour desc limit 1)\n",
    "            ) \n",
    "         where event != 'ExposureBegin' \n",
    "            and epocseconds - strftime(\"%s\", \"{0}\") < 0\n",
    "            order by  abs(strftime(\"%s\", \"{0}\") - epocseconds) \n",
    "            limit 1\n",
    "    \"\"\".format(DateTime), engine) \n",
    "    \n",
    "    df_end = pandas.read_sql_query(make_sql(VelocityDateTime, TrueForBefore=False), engine)\n",
    "    df_end1 = pandas.read_sql_query(\"\"\"select datetime, epocseconds - strftime(\"%s\", \"{0}\"), event from \n",
    "        (select * from telemetry_time_lookup where \n",
    "        YearMonthDayHour =  strftime('%Y-%m-%d-%H', \"{0}\" )) \n",
    "        where event != 'ExposureBegin' \n",
    "        and epocseconds - strftime(\"%s\", \"{0}\") > 0\n",
    "        order by  abs(strftime(\"%s\", \"{0}\") - epocseconds) \n",
    "        limit 1\n",
    "    \"\"\".format(DateTime), engine) \n",
    "    \n",
    "    if printstuff:\n",
    "        print('just prior time: {}'.format(df_begin))\n",
    "        print(df_end)\n",
    "    \n",
    "    no_telemetry_message = 'no telemetry for this time'\n",
    "    if df_begin.empty:\n",
    "        first_timestamp = no_telemetry_message\n",
    "        #raise Exception('df_begin empty for datetimelocal= {}'.format(VelocityDateTime))\n",
    "    else:\n",
    "        just_prior_timestamp = df_begin.DateTime[0]\n",
    "        first_timestamp =  pandas.read_sql_query(\"\"\"\n",
    "            select DateTime from telemetry_time_lookup where\n",
    "            datetime > \"{}\" limit 1\n",
    "            \"\"\".format(just_prior_timestamp), engine).DateTime[0]\n",
    "        \n",
    "    if df_end.empty:\n",
    "        last_timestamp = no_telemetry_message\n",
    "        #raise Exception('df_end empty for datetimelocal= {}'.format(VelocityDateTime))\n",
    "    else:\n",
    "        just_after_timestamp = df_end.DateTime[0]\n",
    "        last_timestamp =  pandas.read_sql_query(\"\"\"\n",
    "            select DateTime from telemetry_time_lookup where\n",
    "            datetime < \"{}\" order by DateTime desc limit 1\n",
    "            \"\"\".format(just_after_timestamp), engine).DateTime[0]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if printstuff:\n",
    "        print(just_prior_timestamp, just_after_timestamp)\n",
    "        print(first_timestamp, last_timestamp)\n",
    "    \n",
    "    return first_timestamp, last_timestamp\n",
    "    \n",
    "\n",
    "def populate_begin_end_times(engine, printstuff=False):\n",
    "    \n",
    "    \n",
    "    velocity_times = pandas.read_sql_query(\"\"\"\n",
    "               select v.datetimelocal from velocity v\n",
    "                 inner join vel_telemetry_stats vt\n",
    "                 on v.datetimelocal = vt.datetimelocal\n",
    "                 where v.datetimelocal > \"2015-01-01T00:00:58.463989\"\n",
    "                 and vt.exposure_begin_datetime is null\n",
    "    \"\"\", engine).DateTimeLocal \n",
    "    \n",
    "    for v_timestamp in velocity_times:\n",
    "        if printstuff:\n",
    "            print('trying {}'.format(v_timestamp))\n",
    "        begin_time, end_time = get_begin_end_times(engine, v_timestamp)\n",
    "        if printstuff:\n",
    "            print('{} {}'.format(begin_time, end_time))\n",
    "        engine.execute(\"\"\"UPDATE vel_telemetry_stats \n",
    "                            SET exposure_begin_datetime = \"{exposure_begin}\",\n",
    "                                exposure_end_datetime = \"{exposure_end}\"\n",
    "                            WHERE DateTimeLocal = \"{v_timestamp}\"\n",
    "                            \"\"\".format(exposure_begin=begin_time, \n",
    "                                      exposure_end=end_time,\n",
    "                                      v_timestamp=v_timestamp))\n",
    "    \n",
    "    print(\"just tried to populate {} rows of begin-end timestamps\".format(len(velocity_times)))\n",
    "\n",
    "#drop_vel_telemetry_stats(engine)\n",
    "#create_vel_telemetry_stats(engine)\n",
    "#populate_only_datetime_vts(engine)\n",
    "\n",
    "populate_begin_end_times(engine, printstuff=True) #this takes a while.\n",
    "\n",
    "\n",
    "\n",
    "#get_begin_end_times(engine, VelocityDateTime='2015-07-20T04:00:58.463989', printstuff=False)\n",
    "#get_begin_end_times(engine, VelocityDateTime='2015-07-25T03:55:50.016014')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting datetime: 2017-01-31T21:40:17.184006\n",
      "select datetime, epocseconds - strftime(\"%s\", \"2017-01-31T21:40:17.184006\"), event from \n",
      "            (select * from telemetry_time_lookup where \n",
      "            YearMonthDayHour =  strftime('%Y-%m-%d-%H', \"2017-01-31T21:40:17.184006\" ) \n",
      "        union all\n",
      "            select * from telemetry_time_lookup where \n",
      "            YearMonthDayHour = (select yearmonthdayhour from telemetry_time_lookup \n",
      "                where YearMonthDayHour < strftime('%Y-%m-%d-%H', \"2017-01-31T21:40:17.184006\") order by \n",
      "                YearMonthDayHour desc limit 1)\n",
      "            ) \n",
      "         where event != 'ExposureBegin' \n",
      "            and epocseconds - strftime(\"%s\", \"2017-01-31T21:40:17.184006\") < 0\n",
      "            order by  abs(strftime(\"%s\", \"2017-01-31T21:40:17.184006\") - epocseconds) \n",
      "            limit 1\n",
      "select datetime, epocseconds - strftime(\"%s\", \"2017-01-31T21:40:17.184006\"), event from \n",
      "            (select * from telemetry_time_lookup where \n",
      "            YearMonthDayHour =  strftime('%Y-%m-%d-%H', \"2017-01-31T21:40:17.184006\" ) \n",
      "        union all\n",
      "            select * from telemetry_time_lookup where \n",
      "            YearMonthDayHour = (select yearmonthdayhour from telemetry_time_lookup \n",
      "                where YearMonthDayHour > strftime('%Y-%m-%d-%H', \"2017-01-31T21:40:17.184006\") order by \n",
      "                YearMonthDayHour asc limit 1)\n",
      "            ) \n",
      "         where event != 'ExposureBegin' \n",
      "            and epocseconds - strftime(\"%s\", \"2017-01-31T21:40:17.184006\") > 0\n",
      "            order by  abs(strftime(\"%s\", \"2017-01-31T21:40:17.184006\") - epocseconds) \n",
      "            limit 1\n",
      "just prior time: Empty DataFrame\n",
      "Columns: [DateTime, epocseconds - strftime(\"%s\", \"2017-01-31T21:40:17.184006\"), Event]\n",
      "Index: []\n",
      "                   DateTime  \\\n",
      "0  2017-02-01T17:00:00.0000   \n",
      "\n",
      "   epocseconds - strftime(\"%s\", \"2017-01-31T21:40:17.184006\")            Event  \n",
      "0                                            69583.0           ControllerReady  \n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "df_begin empty for datetimelocal= 2017-01-31T21:40:17.184006",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-559ab4cb6afa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_begin_end_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2017-01-31T21:40:17.184006\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintstuff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-6a7df2bd8bd8>\u001b[0m in \u001b[0;36mget_begin_end_times\u001b[0;34m(engine, VelocityDateTime, printstuff)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf_begin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_begin empty for datetimelocal= {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVelocityDateTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_end empty for datetimelocal= {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVelocityDateTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: df_begin empty for datetimelocal= 2017-01-31T21:40:17.184006"
     ]
    }
   ],
   "source": [
    "get_begin_end_times(engine, \"2017-01-31T21:40:17.184006\", printstuff=True)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTimeLocal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-31T21:40:17.184006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-31T22:05:37.823997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-31T22:25:00.768001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                DateTimeLocal\n",
       "0  2017-01-31T21:40:17.184006\n",
       "1  2017-01-31T22:05:37.823997\n",
       "2  2017-01-31T22:25:00.768001"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_sql_query(\"\"\"select v.datetimelocal from velocity v\n",
    "                 inner join vel_telemetry_stats vt\n",
    "                 on v.datetimelocal = vt.datetimelocal\n",
    "                 where v.datetimelocal > \"2015-01-01T00:00:58.463989\"\n",
    "                 and vt.exposure_begin_datetime = 'no telemetry for this time'\"\"\", engine)\n",
    "\n",
    "#df = pandas.read_sql_query(\"\"\"select datetime from telemetry_time_lookup where yearmonthdayhour='2017-01-31-21'\n",
    "#                        \n",
    " #                       \"\"\", engine)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_sql_query(\n",
    "\"\"\"SELECT\n",
    "  event,\n",
    "  COUNT(*) AS `num`\n",
    "FROM\n",
    "  (select * from telemetry where \n",
    "                        DateTime between \"2015-02-02T17:00:00.0000\" and \n",
    "                        \"2015-02-03T05:01:00.0000\") \n",
    "GROUP BY\n",
    "  event                  \n",
    "                        \"\"\", engine)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_sql_query(\n",
    "\"\"\"SELECT DateTime, event from (select * from telemetry where DateTime < \"2015-01-02T19:01:00.0000\"\n",
    "    and (event == \"ExposureEnd\" or event == 'ReadoutEnd')) order by datetime\n",
    "limit 100\n",
    "                        \"\"\", engine)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pandas.read_sql_query(\"\"\"\n",
    "#    Select Datetimelocal, Mdptjulian from velocity \n",
    "#    where DateTimeLocal > \"2015-04-01T17:01:00.0000\"\n",
    "#    and DateTimeLocal < \"2015-04-10T17:01:00.0000\"\n",
    "#    order by DateTimeLocal limit 100\n",
    "#\n",
    "#    \"\"\", engine)\n",
    "#df2 = pandas.read_sql_query(\n",
    "#\"\"\"select datetime from telemetry \n",
    "#    order by (abs(strftime('%s',datetime) - abs(strftime('%s',\"2015-04-02T01:31:44.832007\"))))  limit 1\n",
    "#                        \"\"\", engine)\n",
    "\n",
    "#print(df1)\n",
    "\n",
    "print(df2)\n",
    "\n",
    "#print(pandas.read_sql_query(\"\"\"\n",
    "#    Select t.DateTime, v.Datetimelocal, v.Mdptjulian from (velocity v, telemetry t)\n",
    "#    where v.DateTimeLocal > \"2015-04-01T17:01:00.0000\"\n",
    "#    and v.DateTimeLocal < \"2015-04-10T17:01:00.0000\"\n",
    "#    and (t.DateTime - v.DateTi \n",
    "#    order by DateTimeLocal limit 100\n",
    "#\n",
    "#    \"\"\", engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a hi b hi c hi'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"a {0} b {0} c {0}\"\"\".format('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-f359198a64fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2015-01-02T19:01:00.0000\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatestr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type str)"
     ]
    }
   ],
   "source": [
    "datestr = \"2015-01-02T19:01:00.0000\"\n",
    "date.fromtimestamp(datestr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
