{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import sqlite3\n",
    "global_sqlite_filename='apf.db'\n",
    "import pandas\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from sqlalchemy import create_engine\n",
    "import pytz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT\n"
     ]
    }
   ],
   "source": [
    "class col_types:\n",
    "    def __init__(self):\n",
    "        self.TEXT = 'TEXT'\n",
    "        self.INTEGER = 'INTEGER'\n",
    "        self.REAL = 'REAL'\n",
    "        self.BLOB = 'BLOB'\n",
    "        self.NULL = 'NULL'\n",
    "        \n",
    "ct = col_types()\n",
    "print(ct.TEXT)\n",
    "\n",
    "#print(os.getcwd())\n",
    "#print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(sqlite_filename=global_sqlite_filename):\n",
    "    conn = sqlite3.connect(sqlite_filename)\n",
    "    cursor = conn.cursor()\n",
    "    return cursor\n",
    "       \n",
    "def get_telemetry_columns():\n",
    "    columns = {'DateTime': ct.TEXT, \n",
    "                  'TARGET': ct.NULL,\n",
    "                  'MIDPTFIN': ct.REAL,\n",
    "                  'AZ': ct.REAL,\n",
    "                  'EL': ct.REAL,\n",
    "                  'AZENCPOS': ct.REAL,\n",
    "                  'ELENCPOS': ct.REAL,\n",
    "                  'AZENCVEL': ct.REAL,\n",
    "                  'ELENCVEL': ct.REAL,\n",
    "                  'AZFLWERR': ct.REAL,\n",
    "                  'ELFLWERR': ct.REAL,\n",
    "                  'OUTFILE': ct.REAL,\n",
    "                  'OBSNUM': ct.REAL,\n",
    "                  'MODE': ct.REAL,\n",
    "                  'AVG_FWHM': ct.REAL,\n",
    "                  'M5WIND': ct.REAL,\n",
    "                  'M5WINDAZ': ct.REAL,\n",
    "                  'TAVERAGE': ct.REAL,\n",
    "                  'TM1S210': ct.REAL,\n",
    "                  'TM2CAIR': ct.REAL,\n",
    "                  'OFFSET_AZ': ct.REAL,\n",
    "                  'OFFSET_EL': ct.REAL,\n",
    "                  'RMSOFFSET_AZ': ct.REAL,\n",
    "                  'RMSOFFSET_EL': ct.REAL,\n",
    "                  'AVGOFFSET_AZ': ct.REAL,\n",
    "                  'AVGOFFSET_EL': ct.REAL,\n",
    "                  'HATCHPOS': ct.TEXT,\n",
    "                  'EVENT': ct.TEXT}    \n",
    "    return columns\n",
    "    \n",
    "def get_velocity_columns():\n",
    "    columns = [('MdptJulian', ct.REAL),\n",
    "               ('velocity', ct.REAL),\n",
    "               ('velocity_error', ct.REAL),\n",
    "               ('stellar_activity1', ct.REAL),\n",
    "               ('stellar_activity2', ct.REAL),\n",
    "               ('total_counts', ct.REAL),\n",
    "               ('brad_doesnt_know', ct.REAL),\n",
    "               ('DateTimeUTC', ct.TEXT),\n",
    "               ('DateTimeLocal', ct.TEXT),\n",
    "               ('starID', ct.TEXT)\n",
    "              ]\n",
    "    return columns\n",
    "    \n",
    "def create_telemetry_table(cursor):        \n",
    "    columns = get_telemetry_columns()\n",
    "    l = ['{} {}'.format(k,v) for (k, v) in columns.items()]\n",
    "    print(len(l))\n",
    "    full_list = ', '.join(l)\n",
    "    sql_create_string = 'CREATE TABLE telemetry (' + full_list + ', PRIMARY KEY (DateTime))'\n",
    "    print(sql_create_string)        \n",
    "    cursor.execute(sql_create_string)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def create_velocity_table(cursor):\n",
    "    columns = get_velocity_columns()\n",
    "    l = ['{} {}'.format(k,v) for (k, v) in columns]\n",
    "    full_list = ', '.join(l)\n",
    "    sql_create_string = 'CREATE TABLE velocity (' + full_list + ', PRIMARY KEY (DateTimeLocal))'\n",
    "    print(sql_create_string)  \n",
    "    cursor.execute(sql_create_string)\n",
    "\n",
    "    return\n",
    "\n",
    "def open_connection(sqlite_filename=global_sqlite_filename):\n",
    "    dburi = 'file:{}?mode=rw'.format(sqlite_filename)\n",
    "    conn = sqlite3.connect(dburi, uri=True)\n",
    "    return conn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = open_connection()\n",
    "cursor = conn.cursor()\n",
    "#create_telemetry_table(cursor)\n",
    "#create_velocity_table(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_telemetry_table(conn, filenames):\n",
    "    for csv_file in filenames:\n",
    "        try:\n",
    "            df = pandas.read_csv(csv_file, \n",
    "                               sep='\\t', skiprows=1, header=None, names=get_telemetry_columns(), comment='#')\n",
    "            df.to_sql('telemetry', conn, if_exists='append', index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(csv_file)\n",
    "            print(e)\n",
    "\n",
    "def populate_telemetry(conn=None, dirname=None, batchsize=5):\n",
    "    filenames = [os.path.join(dirname, x) for x in os.listdir(dirname)]\n",
    "    filenames.sort()\n",
    "    \n",
    "    def batch(iterable, n=1):\n",
    "        l = len(iterable)\n",
    "        for ndx in range(0, l, n):\n",
    "            yield iterable[ndx : min(ndx + n, l)]\n",
    "    \n",
    "    for file_batch in batch(filenames, n=batchsize):\n",
    "        populate_telemetry_table(conn, file_batch)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate_telemetry(conn, '../telemetry_data', batchsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_velocity_csv(dirname, filename):\n",
    "    full_path = os.path.join(dirname, filename)\n",
    "    columns = get_velocity_columns()[:-2] # leave off the last two column names\n",
    "                                        # because we're calculating them below.\n",
    "    df = pandas.read_csv(full_path, sep='\\s+',\n",
    "            names=[x[0] for x in columns]) \n",
    "                                                \n",
    "    return df\n",
    "    \n",
    "    \n",
    "california_tzinfo = pytz.timezone('US/Pacific')\n",
    "\n",
    "# returns a string for a single julian date. Couldn't figure out how to vectorize.\n",
    "def convert_julian_to_datetime_local(juliantime):\n",
    "    times = Time(juliantime, format='jd')\n",
    "    full_iso = times.to_datetime(timezone=california_tzinfo).isoformat()\n",
    "    return full_iso[:-6]\n",
    "\n",
    "# takes in an array of julian dates. Returns an array of local isot strings.\n",
    "def make_array_of_local_datetimes(julian_array):\n",
    "    output_array = np.empty(len(julian_array), dtype='S26')\n",
    "    for i, julian_time in enumerate(julian_array):\n",
    "        output_array[i] = convert_julian_to_datetime_local(julian_time)\n",
    "    return output_array\n",
    "    \n",
    "\n",
    "def convert_julian_to_datetime_utc(juliantimes):\n",
    "    times = Time(juliantimes, format='jd')\n",
    "    return times.isot \n",
    "    \n",
    "def add_calculated_columns(df, filename):\n",
    "    new_df = df.copy()\n",
    "    #datetimes = convert_julian_to_datetime(new_df.MdptJulian)\n",
    "    new_df['DateTimeUTC'] = convert_julian_to_datetime_utc(new_df.MdptJulian)\n",
    "    new_df['DateTimeLocal'] = make_array_of_local_datetimes(new_df.MdptJulian)\n",
    "    new_df['starID'] = [filename] * len(new_df.index) \n",
    "    \n",
    "    return new_df\n",
    "    \n",
    "\n",
    "def populate_velocity(conn, dirname='../standard_star_velocity_measurements/', debug=False):\n",
    "    filenames = ['HD10700_APF.vels', 'HD185144_APF.vels', 'HD9407_APF.vels']\n",
    "    for file in filenames:\n",
    "        df_incomplete = load_velocity_csv(dirname, file)\n",
    "        df_complete = add_calculated_columns(df_incomplete, file)\n",
    "        if debug:\n",
    "            print(df_complete)\n",
    "        else: \n",
    "            df_complete.to_sql('velocity', conn, if_exists='append', index=False)\n",
    "        print('tried to add {} entries to \\'velocity\\''.format(len(df_complete)))\n",
    "\n",
    "#velocity_df = load_velocity_csv('../standard_star_velocity_measurements/', 'HD10700_APF.vels')\n",
    "#add_calculated_columns(velocity_df, 'HD10700_APF.vels' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tried to add 755 entries to 'velocity'\n",
      "tried to add 1655 entries to 'velocity'\n",
      "tried to add 694 entries to 'velocity'\n"
     ]
    }
   ],
   "source": [
    "#populate_velocity(conn, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create additional calculated columns on velocity\n",
    "engine = create_engine('sqlite:///apf.db', echo=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    DateTime            EVENT\n",
      "0   2015-01-01T17:00:00.0000  ControllerReady\n",
      "1   2015-01-01T17:00:01.0570  ControllerReady\n",
      "2   2015-01-01T17:00:02.1137  ControllerReady\n",
      "3   2015-01-01T17:00:04.0934  ControllerReady\n",
      "4   2015-01-01T17:00:05.1432  ControllerReady\n",
      "5   2015-01-01T17:00:07.0867  ControllerReady\n",
      "6   2015-01-01T17:00:08.0872  ControllerReady\n",
      "7   2015-01-01T17:00:09.9234  ControllerReady\n",
      "8   2015-01-01T17:00:11.0724  ControllerReady\n",
      "9   2015-01-01T17:00:12.0986  ControllerReady\n",
      "10  2015-01-01T17:00:13.1580  ControllerReady\n",
      "11  2015-01-01T17:00:14.9287  ControllerReady\n",
      "12  2015-01-01T17:00:16.0868  ControllerReady\n",
      "13  2015-01-01T17:00:18.1185  ControllerReady\n",
      "14  2015-01-01T17:00:19.9310  ControllerReady\n",
      "15  2015-01-01T17:00:21.0752  ControllerReady\n",
      "16  2015-01-01T17:00:22.0942  ControllerReady\n",
      "17  2015-01-01T17:00:23.1133  ControllerReady\n",
      "18  2015-01-01T17:00:24.9275  ControllerReady\n",
      "19  2015-01-01T17:00:26.0811  ControllerReady\n",
      "20  2015-01-01T17:00:27.4395  ControllerReady\n",
      "21  2015-01-01T17:00:29.0964  ControllerReady\n",
      "22  2015-01-01T17:00:30.6232  ControllerReady\n",
      "23  2015-01-01T17:00:32.0953  ControllerReady\n",
      "24  2015-01-01T17:00:33.3632  ControllerReady\n",
      "25  2015-01-01T17:00:34.4106  ControllerReady\n",
      "26  2015-01-01T17:00:36.0702  ControllerReady\n",
      "27  2015-01-01T17:00:37.0822  ControllerReady\n",
      "28  2015-01-01T17:00:38.0861  ControllerReady\n",
      "29  2015-01-01T17:00:39.9267  ControllerReady\n",
      "30  2015-01-01T17:00:41.0603  ControllerReady\n",
      "31  2015-01-01T17:00:42.1007  ControllerReady\n",
      "32  2015-01-01T17:00:43.2978  ControllerReady\n",
      "33  2015-01-01T17:00:44.9133  ControllerReady\n",
      "34  2015-01-01T17:00:46.0791  ControllerReady\n",
      "35  2015-01-01T17:00:47.0919  ControllerReady\n",
      "36  2015-01-01T17:00:48.1661  ControllerReady\n",
      "37  2015-01-01T17:00:49.9315  ControllerReady\n",
      "38  2015-01-01T17:00:51.0686  ControllerReady\n",
      "39  2015-01-01T17:00:52.1016  ControllerReady\n",
      "40  2015-01-01T17:00:53.1052  ControllerReady\n",
      "41  2015-01-01T17:00:54.9296  ControllerReady\n",
      "42  2015-01-01T17:00:56.0653  ControllerReady\n",
      "43  2015-01-01T17:00:57.0738  ControllerReady\n",
      "44  2015-01-01T17:00:58.0744  ControllerReady\n",
      "45  2015-01-01T17:00:59.1043  ControllerReady\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_sql_query(\"\"\"select DateTime, Event from telemetry \n",
    "                        where DateTime between \"2015-01-01T17:00:00.0000\" and \n",
    "                        \"2015-01-01T17:01:00.0000\" \n",
    "                        \"\"\", engine)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
