{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import sqlite3\n",
    "global_sqlite_filename='apf.db'\n",
    "import pandas\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from sqlalchemy import create_engine\n",
    "import pytz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT\n"
     ]
    }
   ],
   "source": [
    "class col_types:\n",
    "    def __init__(self):\n",
    "        self.TEXT = 'TEXT'\n",
    "        self.INTEGER = 'INTEGER'\n",
    "        self.REAL = 'REAL'\n",
    "        self.BLOB = 'BLOB'\n",
    "        self.NULL = 'NULL'\n",
    "        \n",
    "ct = col_types()\n",
    "print(ct.TEXT)\n",
    "\n",
    "#print(os.getcwd())\n",
    "#print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(sqlite_filename=global_sqlite_filename):\n",
    "    conn = sqlite3.connect(sqlite_filename)\n",
    "    cursor = conn.cursor()\n",
    "    return cursor\n",
    "       \n",
    "def get_telemetry_columns():\n",
    "    columns = {'DateTime': ct.TEXT, \n",
    "                  'TARGET': ct.NULL,\n",
    "                  'MIDPTFIN': ct.REAL,\n",
    "                  'AZ': ct.REAL,\n",
    "                  'EL': ct.REAL,\n",
    "                  'AZENCPOS': ct.REAL,\n",
    "                  'ELENCPOS': ct.REAL,\n",
    "                  'AZENCVEL': ct.REAL,\n",
    "                  'ELENCVEL': ct.REAL,\n",
    "                  'AZFLWERR': ct.REAL,\n",
    "                  'ELFLWERR': ct.REAL,\n",
    "                  'OUTFILE': ct.REAL,\n",
    "                  'OBSNUM': ct.REAL,\n",
    "                  'MODE': ct.REAL,\n",
    "                  'AVG_FWHM': ct.REAL,\n",
    "                  'M5WIND': ct.REAL,\n",
    "                  'M5WINDAZ': ct.REAL,\n",
    "                  'TAVERAGE': ct.REAL,\n",
    "                  'TM1S210': ct.REAL,\n",
    "                  'TM2CAIR': ct.REAL,\n",
    "                  'OFFSET_AZ': ct.REAL,\n",
    "                  'OFFSET_EL': ct.REAL,\n",
    "                  'RMSOFFSET_AZ': ct.REAL,\n",
    "                  'RMSOFFSET_EL': ct.REAL,\n",
    "                  'AVGOFFSET_AZ': ct.REAL,\n",
    "                  'AVGOFFSET_EL': ct.REAL,\n",
    "                  'HATCHPOS': ct.TEXT,\n",
    "                  'EVENT': ct.TEXT}    \n",
    "    return columns\n",
    "    \n",
    "def get_velocity_columns():\n",
    "    columns = [('MdptJulian', ct.REAL),\n",
    "               ('velocity', ct.REAL),\n",
    "               ('velocity_error', ct.REAL),\n",
    "               ('stellar_activity1', ct.REAL),\n",
    "               ('stellar_activity2', ct.REAL),\n",
    "               ('total_counts', ct.REAL),\n",
    "               ('brad_doesnt_know', ct.REAL),\n",
    "               ('DateTimeUTC', ct.TEXT),\n",
    "               ('DateTimeLocal', ct.TEXT),\n",
    "               ('starID', ct.TEXT)\n",
    "              ]\n",
    "    return columns\n",
    "    \n",
    "def create_telemetry_table(cursor):        \n",
    "    columns = get_telemetry_columns()\n",
    "    l = ['{} {}'.format(k,v) for (k, v) in columns.items()]\n",
    "    print(len(l))\n",
    "    full_list = ', '.join(l)\n",
    "    sql_create_string = 'CREATE TABLE telemetry (' + full_list + ', PRIMARY KEY (DateTime))'\n",
    "    print(sql_create_string)        \n",
    "    cursor.execute(sql_create_string)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def create_velocity_table(cursor):\n",
    "    columns = get_velocity_columns()\n",
    "    l = ['{} {}'.format(k,v) for (k, v) in columns]\n",
    "    full_list = ', '.join(l)\n",
    "    sql_create_string = 'CREATE TABLE velocity (' + full_list + ', PRIMARY KEY (DateTimeLocal))'\n",
    "    print(sql_create_string)  \n",
    "    cursor.execute(sql_create_string)\n",
    "\n",
    "    return\n",
    "\n",
    "def open_connection(sqlite_filename=global_sqlite_filename):\n",
    "    dburi = 'file:{}?mode=rw'.format(sqlite_filename)\n",
    "    conn = sqlite3.connect(dburi, uri=True)\n",
    "    return conn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = open_connection()\n",
    "cursor = conn.cursor()\n",
    "#create_telemetry_table(cursor)\n",
    "#create_velocity_table(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_telemetry_table(conn, filenames):\n",
    "    for csv_file in filenames:\n",
    "        try:\n",
    "            df = pandas.read_csv(csv_file, \n",
    "                               sep='\\t', skiprows=1, header=None, names=get_telemetry_columns(), comment='#')\n",
    "            df.to_sql('telemetry', conn, if_exists='append', index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(csv_file)\n",
    "            print(e)\n",
    "\n",
    "def populate_telemetry(conn=None, dirname=None, batchsize=5):\n",
    "    filenames = [os.path.join(dirname, x) for x in os.listdir(dirname)]\n",
    "    filenames.sort()\n",
    "    \n",
    "    def batch(iterable, n=1):\n",
    "        l = len(iterable)\n",
    "        for ndx in range(0, l, n):\n",
    "            yield iterable[ndx : min(ndx + n, l)]\n",
    "    \n",
    "    for file_batch in batch(filenames, n=batchsize):\n",
    "        populate_telemetry_table(conn, file_batch)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate_telemetry(conn, '../telemetry_data', batchsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_velocity_csv(dirname, filename):\n",
    "    full_path = os.path.join(dirname, filename)\n",
    "    columns = get_velocity_columns()[:-2] # leave off the last two column names\n",
    "                                        # because we're calculating them below.\n",
    "    df = pandas.read_csv(full_path, sep='\\s+',\n",
    "            names=[x[0] for x in columns]) \n",
    "                                                \n",
    "    return df\n",
    "    \n",
    "    \n",
    "california_tzinfo = pytz.timezone('US/Pacific')\n",
    "\n",
    "# returns a string for a single julian date. Couldn't figure out how to vectorize.\n",
    "def convert_julian_to_datetime_local(juliantime):\n",
    "    times = Time(juliantime, format='jd')\n",
    "    full_iso = times.to_datetime(timezone=california_tzinfo).isoformat()\n",
    "    return full_iso[:-6]\n",
    "\n",
    "# takes in an array of julian dates. Returns an array of local isot strings.\n",
    "def make_array_of_local_datetimes(julian_array):\n",
    "    output_array = output_array = np.chararray(len(julian_array), itemsize=26, unicode=True)\n",
    "    for i, julian_time in enumerate(julian_array):\n",
    "        output_array[i] = convert_julian_to_datetime_local(julian_time)\n",
    "    return output_array\n",
    "    \n",
    "\n",
    "def convert_julian_to_datetime_utc(juliantimes):\n",
    "    times = Time(juliantimes, format='jd')\n",
    "    return times.isot \n",
    "    \n",
    "def add_calculated_columns(df, filename):\n",
    "    new_df = df.copy()\n",
    "    #datetimes = convert_julian_to_datetime(new_df.MdptJulian)\n",
    "    new_df['DateTimeUTC'] = convert_julian_to_datetime_utc(new_df.MdptJulian)\n",
    "    new_df['DateTimeLocal'] = make_array_of_local_datetimes(new_df.MdptJulian)\n",
    "    new_df['starID'] = [filename] * len(new_df.index) \n",
    "    \n",
    "    return new_df\n",
    "    \n",
    "\n",
    "def populate_velocity(conn, dirname='../standard_star_velocity_measurements/', debug=False):\n",
    "    filenames = ['HD10700_APF.vels', 'HD185144_APF.vels', 'HD9407_APF.vels']\n",
    "    for file in filenames:\n",
    "        print('started {}'.format(file))\n",
    "        df_incomplete = load_velocity_csv(dirname, file)\n",
    "        df_complete = add_calculated_columns(df_incomplete, file)\n",
    "        if debug:\n",
    "            print(df_complete)\n",
    "        else: \n",
    "            df_complete.to_sql('velocity', conn, if_exists='append', index=False)\n",
    "        print('tried to add {} entries to \\'velocity\\''.format(len(df_complete)))\n",
    "\n",
    "#velocity_df = load_velocity_csv('../standard_star_velocity_measurements/', 'HD10700_APF.vels')\n",
    "#add_calculated_columns(velocity_df, 'HD10700_APF.vels' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started HD10700_APF.vels\n",
      "tried to add 755 entries to 'velocity'\n",
      "started HD185144_APF.vels\n",
      "tried to add 1655 entries to 'velocity'\n",
      "started HD9407_APF.vels\n",
      "tried to add 694 entries to 'velocity'\n"
     ]
    }
   ],
   "source": [
    "#populate_velocity(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create additional calculated columns on velocity\n",
    "engine = create_engine('sqlite:///apf.db', echo=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   epocseconds - 1436589861.0       Event\n",
      "0                       -38.0  EraseBegin\n"
     ]
    }
   ],
   "source": [
    "#add new table telemetrytimelookup\n",
    "def drop_telemetry_time_lookup(engine):\n",
    "    engine.execute(\"\"\"DROP TABLE IF EXISTS telemetry_time_lookup;\"\"\")\n",
    "    print('dropped telemetry_time_lookup.')\n",
    "\n",
    "def create_telemetry_time_lookup(engine):\n",
    "    engine.execute(\"\"\"\n",
    "    CREATE TABLE telemetry_time_lookup (\n",
    "    DateTime TEXT PRIMARY KEY,\n",
    "    YearMonthDayHour REAL,\n",
    "    EpocSeconds REAL,\n",
    "    Event TEXT,\n",
    "    ExposureID TEXT,\n",
    "    FOREIGN KEY (DateTime) REFERENCES telemetry(DateTime) \n",
    "    )\"\"\")\n",
    "    print('created telemetry_time_lookup.')\n",
    "\n",
    "def populate_telemetry_time_lookup(engine):   \n",
    "    engine.execute(\"\"\"INSERT INTO telemetry_time_lookup (DateTime,\n",
    "        YearMonthDayHour, EpocSeconds, Event) \n",
    "    SELECT t.DateTime, strftime('%Y-%m-%d-%H', t.datetime), strftime('%s', t.DateTime), t.Event\n",
    "    from telemetry t\n",
    "    \"\"\")\n",
    "    print('populated created telemetry_time_lookup.')\n",
    "    \n",
    "\n",
    "def create_index_in_telemetry_time_lookup(engine):\n",
    "    engine.execute(\"\"\"CREATE INDEX idx_yearmonthdayhour ON \n",
    "        telemetry_time_lookup(YearMonthDayHour, EpocSeconds)\n",
    "    \"\"\")\n",
    "    print('created index on YearMonthDayHour in TTC.')\n",
    "    \n",
    "#drop_telemetry_time_lookup(engine)\n",
    "#create_telemetry_time_lookup(engine)\n",
    "#populate_telemetry_time_lookup(engine)\n",
    "#create_index_in_telemetry_time_lookup(engine)\n",
    "\n",
    "df = pandas.read_sql_query(\"\"\"select epocseconds - 1436589861.0, event from (select * from telemetry_time_lookup\n",
    "    where YearMonthDayHour = '2015-07-11-04') \n",
    "    where event != 'ExposureBegin' \n",
    "    and epocseconds - 1436589861.0 < 0\n",
    "    order by  abs(1436589861.0 - epocseconds) \n",
    "    limit 1\n",
    "    \"\"\", con=engine)\n",
    "pandas.set_option('precision', 18)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-25T18:47:40.1530 2015-01-25T18:47:54.1569\n",
      "2015-07-11T04:43:44.0315 2015-07-11T04:45:00.0195\n",
      "2015-07-11T04:45:44.5452 2015-07-11T04:47:01.0343\n",
      "2015-07-13T04:17:15.0322 2015-07-13T04:18:33.0361\n",
      "2015-07-13T04:19:17.8070 2015-07-13T04:20:39.0369\n",
      "2015-07-20T03:55:33.6658 2015-07-20T03:59:05.0059\n",
      "2015-07-20T03:59:50.1636 2015-07-20T04:01:53.0244\n",
      "2015-07-25T03:52:37.8557 2015-07-25T03:53:10.0094\n",
      "2015-07-25T03:53:56.0402 2015-07-25T03:54:47.0661\n",
      "2015-07-25T03:55:33.6542 2015-07-25T03:56:09.0254\n",
      "2015-07-25T03:56:54.7438 2015-07-25T03:57:38.6509\n",
      "2015-07-25T03:58:24.0362 2015-07-25T03:58:56.0466\n",
      "2015-07-27T03:30:37.8269 2015-07-27T03:33:01.0593\n",
      "2015-07-27T03:33:47.0306 2015-07-27T03:36:06.7471\n",
      "2015-07-31T03:59:47.0480 2015-07-31T04:00:28.0355\n",
      "2015-07-31T04:01:13.0687 2015-07-31T04:01:57.0545\n",
      "2015-07-31T04:02:42.0591 2015-07-31T04:03:26.0637\n",
      "2015-07-31T04:04:11.0542 2015-07-31T04:04:55.0479\n",
      "2015-07-31T04:05:39.8142 2015-07-31T04:06:22.0562\n",
      "2015-08-03T03:05:09.0257 2015-08-03T03:05:46.0466\n",
      "2015-08-03T03:06:31.0351 2015-08-03T03:07:10.0313\n",
      "2015-08-03T03:07:55.0254 2015-08-03T03:08:32.0241\n",
      "2015-08-03T03:09:17.0316 2015-08-03T03:09:55.6291\n",
      "2015-08-03T03:10:41.0304 2015-08-03T03:11:18.0265\n",
      "2015-08-05T03:10:22.0369 2015-08-05T03:10:37.0343\n",
      "2015-08-05T03:11:23.0262 2015-08-05T03:11:41.0294\n",
      "2015-08-05T03:12:26.0477 2015-08-05T03:12:39.0274\n",
      "2015-08-05T03:13:24.0344 2015-08-05T03:13:35.0320\n",
      "2015-08-05T03:14:19.4091 2015-08-05T03:14:42.0509\n",
      "2015-08-10T02:33:46.0426 2015-08-10T02:35:21.0364\n",
      "2015-08-10T02:36:07.7235 2015-08-10T02:37:46.0534\n",
      "2015-08-14T02:10:37.5900 2015-08-14T02:11:30.9664\n",
      "2015-08-14T02:12:16.0503 2015-08-14T02:13:16.0434\n",
      "2015-08-14T02:14:00.2797 2015-08-14T02:15:00.0278\n",
      "2015-08-20T01:56:40.9672 2015-08-20T01:57:38.9690\n",
      "2015-08-20T01:58:24.9541 2015-08-20T01:59:19.9690\n",
      "2015-08-20T02:00:05.9791 2015-08-20T02:00:57.9496\n",
      "2015-08-25T01:29:39.0271 2015-08-25T01:30:34.0251\n",
      "2015-08-25T01:31:20.0314 2015-08-25T01:32:14.0338\n",
      "2015-08-25T01:33:00.0251 2015-08-25T01:33:55.0413\n",
      "2015-08-29T01:34:54.0435 2015-08-29T01:35:49.0261\n",
      "2015-08-29T01:36:34.1238 2015-08-29T01:37:18.0334\n",
      "2015-08-29T01:38:03.0314 2015-08-29T01:38:47.0440\n",
      "2015-08-29T01:39:32.7416 2015-08-29T01:40:19.0366\n",
      "2015-08-29T01:41:05.0300 2015-08-29T01:41:53.0352\n",
      "2015-09-05T01:05:44.0319 2015-09-05T01:06:36.0299\n",
      "2015-09-05T01:07:21.0340 2015-09-05T01:08:11.0391\n",
      "2015-09-05T01:08:56.0464 2015-09-05T01:09:42.0382\n",
      "2015-09-05T01:10:28.0214 2015-09-05T01:11:11.0436\n",
      "2015-09-05T01:11:57.0354 2015-09-05T01:12:47.4527\n",
      "2015-09-07T00:40:00.0239 2015-09-07T00:41:39.0362\n",
      "2015-09-07T00:42:23.3849 2015-09-07T00:44:09.0373\n",
      "2015-09-10T05:24:01.8603 2015-09-10T05:24:34.2671\n",
      "2015-09-10T05:25:26.6128 2015-09-10T05:26:04.2597\n",
      "2015-09-10T05:26:50.7564 2015-09-10T05:27:29.2563\n",
      "2015-09-15T05:05:13.6490 2015-09-15T05:06:08.6403\n",
      "2015-09-15T05:06:53.3799 2015-09-15T05:07:58.6480\n",
      "2015-09-15T05:08:43.4256 2015-09-15T05:10:03.6499\n",
      "2015-09-19T23:48:56.0519 2015-09-19T23:49:42.9231\n",
      "2015-09-19T23:50:29.6407 2015-09-19T23:51:17.9249\n",
      "2015-09-19T23:52:07.9155 2015-09-19T23:52:52.9190\n",
      "2015-09-19T23:53:38.3062 2015-09-19T23:54:27.9192\n",
      "2015-09-19T23:55:15.3220 2015-09-19T23:56:02.9222\n",
      "2015-09-25T23:26:43.7615 2015-09-25T23:27:35.0472\n",
      "2015-09-25T23:28:25.0576 2015-09-25T23:29:20.0716\n",
      "2015-09-25T23:30:07.6159 2015-09-25T23:31:05.0965\n",
      "2015-09-25T23:31:52.9020 2015-09-25T23:32:55.1039\n",
      "2015-09-25T23:33:41.3833 2015-09-25T23:34:30.1021\n",
      "2015-10-02T23:03:47.8483 2015-10-02T23:08:26.8915\n",
      "2015-10-02T23:09:14.9627 2015-10-02T23:13:56.9022\n",
      "2015-10-02T23:14:45.1049 2015-10-02T23:18:46.9001\n",
      "2015-10-05T02:44:45.1353 2015-10-05T02:47:52.8072\n",
      "2015-10-05T02:48:40.2517 2015-10-05T02:51:52.8151\n",
      "2015-10-05T02:52:40.3783 2015-10-05T02:55:42.8160\n",
      "2015-10-09T02:55:36.7376 2015-10-09T03:03:05.0703\n",
      "2015-10-09T03:03:52.0122 2015-10-09T03:08:45.0653\n",
      "2015-10-09T03:09:33.7986 2015-10-09T03:13:10.0674\n",
      "2015-10-09T03:13:58.3411 2015-10-09T03:18:00.0635\n",
      "2015-10-09T03:18:44.7111 2015-10-09T03:21:40.0635\n",
      "2015-10-11T22:24:10.2585 2015-10-11T22:27:22.8507\n",
      "2015-10-11T22:28:12.8589 2015-10-11T22:31:27.8545\n",
      "2015-10-11T22:32:14.5083 2015-10-11T22:35:27.8589\n",
      "2015-10-20T21:50:08.2403 2015-10-20T21:54:54.7996\n",
      "2015-10-20T21:55:44.7952 2015-10-20T22:00:29.8043\n",
      "2015-10-20T22:01:18.7359 2015-10-20T22:06:04.7952\n",
      "2015-10-20T22:06:58.3941 2015-10-20T22:11:59.8033\n",
      "2015-10-20T22:12:49.7946 2015-10-20T22:17:24.7935\n",
      "2015-10-24T21:37:26.2620 2015-10-24T21:54:49.3096\n",
      "2015-10-24T21:57:07.6460 2015-10-24T22:14:13.6485\n",
      "2015-10-24T22:17:51.5248 2015-10-24T22:35:45.0300\n",
      "2015-10-24T22:56:00.1799 2015-10-24T23:15:56.0402\n",
      "2015-11-04T19:53:31.6985 2015-11-04T19:54:48.8394\n",
      "2015-11-04T19:55:35.8177 2015-11-04T19:56:58.8471\n",
      "2015-11-06T20:38:59.5712 2015-11-06T20:39:23.3240\n",
      "2015-11-06T20:40:11.7640 2015-11-06T20:40:38.3362\n",
      "2015-11-06T20:41:22.8432 2015-11-06T20:41:48.3298\n",
      "2015-11-06T20:42:34.9980 2015-11-06T20:43:03.3334\n",
      "2015-11-06T20:43:53.3384 2015-11-06T20:44:13.3294\n",
      "2015-11-11T21:46:56.0587 2015-11-11T21:47:33.2035\n",
      "2015-11-11T21:48:17.3480 2015-11-11T21:48:53.2028\n",
      "2015-11-11T21:49:43.1962 2015-11-11T21:50:08.2044\n",
      "2015-11-11T21:51:03.2038 2015-11-11T21:51:23.2045\n",
      "2015-11-11T21:52:10.3337 2015-11-11T21:52:38.1995\n",
      "2015-11-14T19:42:45.6230 2015-11-14T19:43:08.7523\n",
      "2015-11-14T19:44:03.7576 2015-11-14T19:44:18.7596\n",
      "2015-11-14T19:45:08.7581 2015-11-14T19:45:28.7526\n",
      "2015-11-14T19:46:15.3073 2015-11-14T19:46:38.7587\n",
      "2015-11-14T19:47:23.5548 2015-11-14T19:47:33.7671\n",
      "2015-11-19T19:18:13.9169 2015-11-19T19:19:11.4066\n",
      "2015-11-19T19:29:40.6583 2015-11-19T19:30:36.4061\n",
      "2015-11-19T19:31:23.2797 2015-11-19T19:32:11.4050\n",
      "2015-11-19T19:32:59.4077 2015-11-19T19:34:01.4072\n",
      "2015-11-26T18:50:23.5112 2015-11-26T18:55:17.3573\n",
      "2015-11-26T18:56:06.9128 2015-11-26T19:01:22.3648\n",
      "2015-11-26T19:09:02.1673 2015-11-26T19:14:42.4053\n",
      "2015-11-28T18:40:57.4099 2015-11-28T18:42:08.0070\n",
      "2015-11-28T18:42:58.0178 2015-11-28T18:44:08.0060\n",
      "2015-11-28T18:44:54.2744 2015-11-28T18:46:13.0306\n",
      "2015-12-01T17:00:00.0000 2015-12-01T17:00:33.9304\n",
      "2015-12-01T17:00:00.0000 2015-12-01T17:00:33.9304\n",
      "2015-12-01T17:00:00.0000 2015-12-01T17:00:33.9304\n",
      "2016-01-27T17:00:00.0000 2016-01-26T17:00:00.0000\n",
      "2016-01-27T17:00:00.0000 2016-01-26T17:00:00.0000\n",
      "2016-01-27T17:00:00.0000 2016-01-26T17:00:00.0000\n",
      "2016-02-05T17:00:00.0000 2016-02-04T17:00:00.0000\n",
      "2016-02-05T17:00:00.0000 2016-02-04T17:00:00.0000\n",
      "2016-02-05T17:00:00.0000 2016-02-04T17:00:00.0000\n",
      "2016-02-07T17:00:00.0000 2016-02-06T17:00:00.0000\n",
      "2016-02-07T17:00:00.0000 2016-02-06T17:00:00.0000\n",
      "2016-02-07T17:00:00.0000 2016-02-06T17:00:00.0000\n",
      "2016-02-10T17:00:00.0000 2016-02-09T17:00:00.0000\n",
      "2016-02-10T17:00:00.0000 2016-02-09T17:00:00.0000\n",
      "2016-07-08T04:36:17.0743 2016-07-08T04:40:47.0252\n",
      "2016-07-08T04:41:31.5363 2016-07-08T04:45:29.0242\n",
      "2016-07-08T04:46:14.0206 2016-07-08T04:49:05.6793\n",
      "2016-07-11T04:24:03.0253 2016-07-11T04:25:21.0271\n",
      "2016-07-11T04:26:09.0221 2016-07-11T04:27:11.0225\n",
      "2016-07-11T04:27:56.7327 2016-07-11T04:29:14.1276\n",
      "2016-07-14T04:33:37.0185 2016-07-14T04:34:33.0209\n",
      "2016-07-14T04:35:18.0169 2016-07-14T04:36:13.0211\n",
      "2016-07-14T04:37:00.0245 2016-07-14T04:37:58.0219\n",
      "2016-07-16T04:32:00.4617 2016-07-16T04:32:53.0237\n",
      "2016-07-16T04:33:39.0240 2016-07-16T04:34:31.4524\n",
      "2016-07-16T04:35:17.0833 2016-07-16T04:36:06.0235\n",
      "2016-07-20T04:29:25.1760 2016-07-20T04:31:06.0213\n",
      "2016-07-20T04:31:53.0207 2016-07-20T04:33:39.0643\n",
      "2016-07-20T04:34:25.3015 2016-07-20T04:36:09.0171\n",
      "2016-07-20T04:36:55.0187 2016-07-20T04:38:39.0179\n",
      "2016-07-20T04:39:26.0142 2016-07-20T04:41:00.0382\n",
      "2016-07-20T04:41:45.9939 2016-07-20T04:43:03.7244\n",
      "2016-07-20T04:43:48.2893 2016-07-20T04:44:59.0634\n",
      "2016-07-23T03:51:04.0715 2016-07-23T03:52:24.0205\n",
      "2016-07-23T03:53:09.0198 2016-07-23T03:54:28.0150\n",
      "2016-07-23T03:55:12.9522 2016-07-23T03:56:27.0270\n",
      "2016-07-23T03:57:14.0182 2016-07-23T03:58:27.1702\n",
      "2016-07-23T03:59:12.9700 2016-07-23T04:00:30.0216\n",
      "2016-07-25T04:09:01.0243 2016-07-25T04:10:08.0166\n",
      "2016-07-25T04:10:52.4171 2016-07-25T04:12:00.0140\n",
      "2016-07-25T04:12:45.0215 2016-07-25T04:13:51.0222\n",
      "2016-07-25T04:14:36.0261 2016-07-25T04:15:40.0202\n",
      "2016-08-04T03:10:34.0496 2016-08-04T03:12:20.0517\n",
      "2016-08-04T03:13:06.0241 2016-08-04T03:14:48.0213\n",
      "2016-08-04T03:15:32.7446 2016-08-04T03:17:14.0184\n",
      "2016-08-04T03:17:59.3076 2016-08-04T03:19:45.0160\n",
      "2016-08-04T03:20:32.6979 2016-08-04T03:22:18.0136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-06T04:11:38.0173 2016-08-06T04:13:14.4291\n",
      "2016-08-06T04:14:01.0236 2016-08-06T04:15:12.0219\n",
      "2016-08-06T04:15:58.0004 2016-08-06T04:17:12.0238\n",
      "2016-08-06T04:17:58.1982 2016-08-06T04:19:10.0215\n",
      "2016-08-06T04:19:56.0298 2016-08-06T04:21:05.0264\n",
      "2016-08-09T02:52:12.0287 2016-08-09T02:53:54.7694\n",
      "2016-08-09T02:54:40.0764 2016-08-09T02:56:23.0199\n",
      "2016-08-09T02:57:08.0224 2016-08-09T02:58:52.2940\n",
      "2016-08-09T02:59:37.5367 2016-08-09T03:01:21.0273\n",
      "2016-08-09T03:02:05.5278 2016-08-09T03:03:39.0249\n",
      "2016-08-12T03:39:24.1932 2016-08-12T03:40:24.0058\n",
      "2016-08-12T03:41:09.0810 2016-08-12T03:42:15.3395\n",
      "2016-08-12T03:43:00.3497 2016-08-12T03:44:05.3346\n",
      "2016-08-12T03:44:51.0268 2016-08-12T03:45:59.0075\n",
      "2016-08-12T03:46:44.1716 2016-08-12T03:47:47.0181\n",
      "2016-08-15T03:56:44.0236 2016-08-15T03:57:49.0202\n",
      "2016-08-15T03:58:35.0210 2016-08-15T03:59:46.0126\n",
      "2016-08-15T04:00:30.2175 2016-08-15T04:01:39.7302\n",
      "2016-08-15T04:02:26.0227 2016-08-15T04:03:35.0226\n",
      "2016-08-15T04:04:22.0161 2016-08-15T04:05:37.0246\n",
      "2016-08-23T03:22:34.0141 2016-08-23T03:24:42.7197\n",
      "2016-08-23T03:25:29.0205 2016-08-23T03:27:34.0068\n",
      "2016-08-23T03:28:20.0157 2016-08-23T03:30:26.0142\n",
      "2016-08-23T03:31:12.7228 2016-08-23T03:33:17.7166\n",
      "2016-08-23T03:34:04.0207 2016-08-23T03:36:06.0226\n",
      "2016-08-24T02:27:50.0203 2016-08-24T02:30:20.0246\n",
      "2016-08-24T02:31:04.6260 2016-08-24T02:33:23.6315\n",
      "2016-08-24T02:34:09.0172 2016-08-24T02:36:31.0241\n",
      "2016-08-24T02:37:17.2880 2016-08-24T02:39:57.0155\n",
      "2016-08-24T02:40:43.0212 2016-08-24T02:42:59.7680\n",
      "2016-08-26T03:07:16.3375 2016-08-26T03:08:18.0182\n",
      "2016-08-26T03:09:03.3309 2016-08-26T03:10:06.3298\n",
      "2016-08-26T03:10:52.2810 2016-08-26T03:12:00.0164\n",
      "2016-08-26T03:12:45.0075 2016-08-26T03:13:51.0151\n",
      "2016-08-26T03:14:37.1281 2016-08-26T03:15:40.0210\n"
     ]
    }
   ],
   "source": [
    "def drop_vel_telemetry_stats(engine):\n",
    "    engine.execute(\"\"\"DROP TABLE IF EXISTS vel_telemetry_stats;\"\"\")\n",
    "    print('dropped vel_telemetry_stats.')\n",
    "\n",
    "def create_vel_telemetry_stats(engine):\n",
    "    engine.execute(\"\"\"\n",
    "    CREATE TABLE vel_telemetry_stats (\n",
    "                  DateTimeLocal TEXT PRIMARY KEY,\n",
    "                  YearMonthDayHour TEXT,\n",
    "                  EpocSeconds REAL,\n",
    "                  ExposureID TEXT,\n",
    "                  exposure_begin_datetime TEXT,\n",
    "                  exposure_end_datetime TEXT\n",
    "                  EL_AVG REAL, EL_STD REAL,\n",
    "                  AZENCPOS_AVG REAL, AZENCPOS_STD REAL\n",
    "                  ELENCPOS_AVG REAL, ELENCPOS_STD REAL,\n",
    "                  AZENCVEL_AVG REAL, AZENCVEL_STD REAL,\n",
    "                  ELENCVEL_AVG REAL, ELENCVEL_STD REAL,\n",
    "                  AZFLWERR_AVG REAL, AZFLWERR_STD REAL,\n",
    "                  ELFLWERR_AVG REAL, ELFLWERR_STD REAL,\n",
    "                  AVG_FWHM_AVG REAL, AVG_FWHM_STD REAL,\n",
    "                  M5WIND_AVG REAL, M5WIND_STD REAL,\n",
    "                  M5WINDAZ_AVG REAL, M5WINDAZ_STD REAL,\n",
    "                  TAVERAGE_AVG REAL, TAVERAGE_STD REAL,\n",
    "                  TM1S210_AVG REAL, TM1S210_STD REAL,\n",
    "                  TM2CAIR_AVG REAL, TM2CAIR_STD REAL,\n",
    "                  OFFSET_AZ_AVG REAL, OFFSET_AZ_STD REAL,\n",
    "                  OFFSET_EL_AVG REAL, OFFSET_EL_STD REAL,\n",
    "                  RMSOFFSET_AZ_AVG REAL, RMSOFFSET_AZ_STD REAL,\n",
    "                  RMSOFFSET_EL_AVG REAL, RMSOFFSET_EL_STD REAL,\n",
    "                  AVGOFFSET_AZ_AVG REAL, AVGOFFSET_AZ_STD REAL,\n",
    "                  AVGOFFSET_EL_AVG REAL, AVGOFFSET_EL_STD REAL,\n",
    "                  Delta_temp_from_begin_night REAL, \n",
    "    FOREIGN KEY (DateTimeLocal) REFERENCES velocity(DateTimeLocal) \n",
    "    )\"\"\")\n",
    "    print('created vel_telemetry_stats')\n",
    "    return\n",
    "\n",
    "def get_begin_end_exposure_datetimes(YearMonthDayHour, epocseconds, engine):\n",
    "    df_begin = pandas.read_sql_query(\"\"\"select epocseconds - {}, event from (select * from telemetry_time_lookup\n",
    "    where YearMonthDayHour = {1}) \n",
    "    where event != 'ExposureBegin' \n",
    "    and epocseconds - {0} < 0\n",
    "    order by  abs({0} - epocseconds) \n",
    "    limit 1\n",
    "    \"\"\".format(), con=engine)\n",
    "    \n",
    "    df_end = pandas.read_sql_query(\"\"\"select epocseconds - {}, event from (select * from telemetry_time_lookup\n",
    "    where YearMonthDayHour = {1}) \n",
    "    where event != 'ExposureBegin' \n",
    "    and epocseconds - {0} > 0\n",
    "    order by  abs({0} - epocseconds) \n",
    "    limit 1\n",
    "    \"\"\".format(), con=engine)\n",
    "    \n",
    "    return df_begin, df_end\n",
    "\n",
    "def populate_only_datetime_vts(engine):\n",
    "    engine.execute(\"\"\"Insert into vel_telemetry_stats\n",
    "                                    (DateTimeLocal, YearMonthDayHour, EpocSeconds)\n",
    "                                    select v.DateTimeLocal, \n",
    "                                        strftime('%Y-%m-%d-%H', v.DateTimeLocal), \n",
    "                                        strftime('%s', v.DateTimeLocal)\n",
    "                                    from velocity v\n",
    "                                    where v.DateTimeLocal > \"2015-01-01T17:00:00\" \"\"\")\n",
    "    print(pandas.read_sql_query(\"\"\"select * from vel_telemetry_stats order by datetimelocal desc limit 10\"\"\", engine))\n",
    "    \n",
    "def get_begin_end_times(engine, VelocityDateTime, printstuff=False):\n",
    "    DateTime = VelocityDateTime\n",
    "    if printstuff:\n",
    "        print('central datetime: {}'.format(DateTime))\n",
    "        \n",
    "    def make_sql(DateTime, TrueForBefore=True):\n",
    "        if TrueForBefore:\n",
    "            greaterthan = '<'\n",
    "            ordering = 'desc'\n",
    "        else:\n",
    "            greaterthan = '>'\n",
    "            ordering = 'asc'\n",
    "        output = \"\"\"select datetime, epocseconds - strftime(\"%s\", \"{0}\"), event from \n",
    "            (select * from telemetry_time_lookup where \n",
    "            YearMonthDayHour =  strftime('%Y-%m-%d-%H', \"{0}\" ) \n",
    "        union all\n",
    "            select * from telemetry_time_lookup where \n",
    "            YearMonthDayHour = (select yearmonthdayhour from telemetry_time_lookup \n",
    "                where YearMonthDayHour {1} strftime('%Y-%m-%d-%H', \"{0}\") order by \n",
    "                YearMonthDayHour {2} limit 1)\n",
    "            ) \n",
    "         where event != 'ExposureBegin' \n",
    "            and epocseconds - strftime(\"%s\", \"{0}\") {1} 0\n",
    "            order by  abs(strftime(\"%s\", \"{0}\") - epocseconds) \n",
    "            limit 1\"\"\".format(DateTime, greaterthan, ordering)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    if printstuff:\n",
    "        print(make_sql(VelocityDateTime, TrueForBefore=True))\n",
    "    \n",
    "    df_begin = pandas.read_sql_query(make_sql(VelocityDateTime, TrueForBefore=True), engine)\n",
    "    df_begin1 = pandas.read_sql_query(\"\"\"select datetime, epocseconds - strftime(\"%s\", \"{0}\"), event from \n",
    "            (select * from telemetry_time_lookup where \n",
    "            YearMonthDayHour =  strftime('%Y-%m-%d-%H', \"{0}\" ) \n",
    "        union all\n",
    "            select * from telemetry_time_lookup where \n",
    "            YearMonthDayHour = (select yearmonthdayhour from telemetry_time_lookup \n",
    "                where YearMonthDayHour < strftime('%Y-%m-%d-%H', \"{0}\") order by \n",
    "                YearMonthDayHour desc limit 1)\n",
    "            ) \n",
    "         where event != 'ExposureBegin' \n",
    "            and epocseconds - strftime(\"%s\", \"{0}\") < 0\n",
    "            order by  abs(strftime(\"%s\", \"{0}\") - epocseconds) \n",
    "            limit 1\n",
    "    \"\"\".format(DateTime), engine) \n",
    "    \n",
    "    df_end = pandas.read_sql_query(make_sql(VelocityDateTime, TrueForBefore=False), engine)\n",
    "    df_end1 = pandas.read_sql_query(\"\"\"select datetime, epocseconds - strftime(\"%s\", \"{0}\"), event from \n",
    "        (select * from telemetry_time_lookup where \n",
    "        YearMonthDayHour =  strftime('%Y-%m-%d-%H', \"{0}\" )) \n",
    "        where event != 'ExposureBegin' \n",
    "        and epocseconds - strftime(\"%s\", \"{0}\") > 0\n",
    "        order by  abs(strftime(\"%s\", \"{0}\") - epocseconds) \n",
    "        limit 1\n",
    "    \"\"\".format(DateTime), engine) \n",
    "    \n",
    "    if printstuff:\n",
    "        print('just prior time: {}'.format(df_begin))\n",
    "        print(df_end)\n",
    "    \n",
    "    just_prior_timestamp = df_begin.DateTime[0]\n",
    "    just_after_timestamp = df_end.DateTime[0]\n",
    "   \n",
    "    \n",
    "    first_timestamp =  pandas.read_sql_query(\"\"\"\n",
    "    select DateTime from telemetry_time_lookup where\n",
    "    datetime > \"{}\" limit 1\n",
    "    \"\"\".format(just_prior_timestamp), engine).DateTime[0]\n",
    "    \n",
    "    last_timestamp =  pandas.read_sql_query(\"\"\"\n",
    "    select DateTime from telemetry_time_lookup where\n",
    "    datetime < \"{}\" order by DateTime desc limit 1\n",
    "    \"\"\".format(just_after_timestamp), engine).DateTime[0]\n",
    "    \n",
    "    if printstuff:\n",
    "        print(just_prior_timestamp, just_after_timestamp)\n",
    "        print(first_timestamp, last_timestamp)\n",
    "    \n",
    "    return first_timestamp, last_timestamp\n",
    "    \n",
    "\n",
    "def populate_begin_end_times(engine, printstuff=False):\n",
    "    \n",
    "    \n",
    "    velocity_times = pandas.read_sql_query(\"\"\"\n",
    "                SELECT DateTimeLocal from velocity \n",
    "                where DateTimeLocal > \"2015-01-01T16:00:00\"\n",
    "    \"\"\", engine).DateTimeLocal \n",
    "    \n",
    "    for v_timestamp in velocity_times[:200]:\n",
    "        begin_time, end_time = get_begin_end_times(engine, v_timestamp)\n",
    "        if printstuff:\n",
    "            print(begin_time, end_time)\n",
    "    \n",
    "    #print(velocity_times)\n",
    "\n",
    "#drop_vel_telemetry_stats(engine)\n",
    "#create_vel_telemetry_stats(engine)\n",
    "#populate_only_datetime_vts(engine)\n",
    "\n",
    "populate_begin_end_times(engine, printstuff=True)\n",
    "\n",
    "\n",
    "\n",
    "#get_begin_end_times(engine, VelocityDateTime='2015-07-20T04:00:58.463989', printstuff=False)\n",
    "#get_begin_end_times(engine, VelocityDateTime='2015-07-25T03:55:50.016014')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   DateTime  \\\n",
      "0  2015-07-20T03:59:49.0316   \n",
      "\n",
      "   epocseconds - strftime(\"%s\", \"2015-07-20T04:00:58.463989\")       Event  \n",
      "0                                              -69.0           EraseBegin  \n"
     ]
    }
   ],
   "source": [
    " df = pandas.read_sql_query(\"\"\"select datetime, epocseconds - strftime(\"%s\", \"{0}\"), event from \n",
    "            (select * from telemetry_time_lookup where \n",
    "            YearMonthDayHour =  strftime('%Y-%m-%d-%H', \"{0}\" ) \n",
    "        union all\n",
    "            select * from telemetry_time_lookup where \n",
    "            YearMonthDayHour = (select yearmonthdayhour from telemetry_time_lookup \n",
    "                where YearMonthDayHour < strftime('%Y-%m-%d-%H', \"{0}\") order by \n",
    "                YearMonthDayHour desc limit 1)\n",
    "            ) \n",
    "         where event != 'ExposureBegin' \n",
    "            and epocseconds - strftime(\"%s\", \"{0}\") < 0\n",
    "            order by  abs(strftime(\"%s\", \"{0}\") - epocseconds) \n",
    "            limit 1\n",
    "    \"\"\".format('2015-07-20T04:00:58.463989'), engine) \n",
    "    \n",
    "    \n",
    "    \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        where event != 'ExposureBegin' \n",
    "        and epocseconds - strftime(\"%s\", \"{0}\") < 0\n",
    "        order by  abs(strftime(\"%s\", \"{0}\") - epocseconds) \n",
    "        limit 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_sql_query(\"\"\"select distinct event from \n",
    "                        (select event from telemetry where \n",
    "                        DateTime between \"2015-01-01T17:00:00.0000\" and \n",
    "                        \"2015-01-02T19:01:00.0000\") \n",
    "                   \n",
    "                        \n",
    "                        \"\"\", engine)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_sql_query(\n",
    "\"\"\"SELECT\n",
    "  event,\n",
    "  COUNT(*) AS `num`\n",
    "FROM\n",
    "  (select * from telemetry where \n",
    "                        DateTime between \"2015-02-02T17:00:00.0000\" and \n",
    "                        \"2015-02-03T05:01:00.0000\") \n",
    "GROUP BY\n",
    "  event                  \n",
    "                        \"\"\", engine)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_sql_query(\n",
    "\"\"\"SELECT DateTime, event from (select * from telemetry where DateTime < \"2015-01-02T19:01:00.0000\"\n",
    "    and (event == \"ExposureEnd\" or event == 'ReadoutEnd')) order by datetime\n",
    "limit 100\n",
    "                        \"\"\", engine)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pandas.read_sql_query(\"\"\"\n",
    "#    Select Datetimelocal, Mdptjulian from velocity \n",
    "#    where DateTimeLocal > \"2015-04-01T17:01:00.0000\"\n",
    "#    and DateTimeLocal < \"2015-04-10T17:01:00.0000\"\n",
    "#    order by DateTimeLocal limit 100\n",
    "#\n",
    "#    \"\"\", engine)\n",
    "#df2 = pandas.read_sql_query(\n",
    "#\"\"\"select datetime from telemetry \n",
    "#    order by (abs(strftime('%s',datetime) - abs(strftime('%s',\"2015-04-02T01:31:44.832007\"))))  limit 1\n",
    "#                        \"\"\", engine)\n",
    "\n",
    "#print(df1)\n",
    "\n",
    "print(df2)\n",
    "\n",
    "#print(pandas.read_sql_query(\"\"\"\n",
    "#    Select t.DateTime, v.Datetimelocal, v.Mdptjulian from (velocity v, telemetry t)\n",
    "#    where v.DateTimeLocal > \"2015-04-01T17:01:00.0000\"\n",
    "#    and v.DateTimeLocal < \"2015-04-10T17:01:00.0000\"\n",
    "#    and (t.DateTime - v.DateTi \n",
    "#    order by DateTimeLocal limit 100\n",
    "#\n",
    "#    \"\"\", engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a hi b hi c hi'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"a {0} b {0} c {0}\"\"\".format('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-f359198a64fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2015-01-02T19:01:00.0000\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatestr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type str)"
     ]
    }
   ],
   "source": [
    "datestr = \"2015-01-02T19:01:00.0000\"\n",
    "date.fromtimestamp(datestr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
